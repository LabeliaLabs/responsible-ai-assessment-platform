{
    "version": "0.55",
    "name": "assessment-dsrc",
    "timestamp": "22-Sep-2020 (15:38:57.929706)",
	"language": "fr",
    "sections": {
        "section 1": {
            "order_id": "1",
            "name": "Protéger les données personnelles ou confidentielles",
            "description": "L'utilisation de données personnelles ou confidentielles fait porter le risque d'exposition de celles-ci, ce qui peut avoir des conséquences très préjudiciables pour les producteurs, gestionnaires, ou sujets de ces données. En particulier dans les projets de data science, elles doivent donc être protégées et les risques qu'elles fuitent ou soient exposées doivent être minimisés.",
            "elements": {
                "element 1": {
                    "order_id": "1",
                    "name": "Législation et exigences contractuelles applicables - Identification",
                    "condition": "n/a",
                    "question_text": "En ce qui concerne les données personnelles et/ou confidentielles, les exigences légales, statutaires, réglementaires et contractuelles en vigueur et concernant votre organisation sont :",
                    "question_type": "radio",
                    "answer_hint": "Sélectionner une seule réponse, correspondant le mieux au niveau de maturité de l'organisation sur ce sujet",
                    "explanation_text": "Il est crucial de mettre en place des processus pour connaître et suivre l'évolution des réglementations applicables (très spécifiques dans certains domaines, par exemple dans le secteur bancaire), ainsi que pour documenter les approches et choix retenus pour être en conformité à chaque projet de data science. Exemple(s) intéressant(s) : [Welfare surveillance system violates human rights, Dutch court rules](https://www.theguardian.com/technology/2020/feb/05/welfare-surveillance-system-violates-human-rights-dutch-court-rules).",
                    "resources": {
                        "0": {
                            "resource_type": "Official report",
                            "resource_text": "[Big data, artificial intelligence, machine learning and data protection](https://ico.org.uk/media/for-organisations/documents/2013559/big-data-ai-ml-and-data-protection.pdf), EU Information Commissioner's Office, 2017"
                        },
                        "1": {
                            "resource_type": "Web article",
                            "resource_text": "[Artificial Intelligence and the GDPR: how do they interact?](https://www.avocats-mathias.com/technologies-avancees/artificial-intelligence-gdpr), Mathias Avocats, Novembre 2017"
                        },
                        "2": {
                            "resource_type": "Web article",
                            "resource_text": "[How to develop Artificial Intelligence that is GDPR-friendly](https://techgdpr.com/blog/develop-artificial-intelligence-ai-gdpr-friendly/), Tech GDRP blog, Février 2019"
                        },
                        "3": {
                            "resource_type": "Video",
                            "resource_text": "[What is the impact of GDPR on AI and Machine Learning?](https://www.youtube.com/watch?v=RLEtyfmsfs4&app=desktop), SwissAI Machine Learning Meetup, Septembre 2018"
                        }
                    },
                    "answer_items": {
                        "1.1.a": {
                            "order_id": "a",
                            "answer_text": "Pas encore identifiées",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "1.1.b": {
                            "order_id": "b",
                            "answer_text": "Partiellement identifiées ou en cours d'identification",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "1.1.c": {
                            "order_id": "c",
                            "answer_text": "Identifiées",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "1.1.d": {
                            "order_id": "d",
                            "answer_text": "Identifiées et maîtrisées par les collaborateurs",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "1.1.e": {
                            "order_id": "e",
                            "answer_text": "Identifiées, documentées et maîtrisées par les collaborateurs",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        }
                    }
                },
                "element 2": {
                    "order_id": "2",
                    "name": "Législation et exigences contractuelles applicables - Approche de mise en conformité",
                    "condition": "n/a",
                    "question_text": "Pour satisfaire à ces exigences, l’approche adoptée par votre organisation est :",
                    "question_type": "radio",
                    "answer_hint": "Sélectionner une seule réponse, correspondant le mieux au niveau de maturité de l'organisation sur ce sujet",
                    "explanation_text": "Il s'agit de s'interroger sur la gestion des données personnelles ou confidentielles (stockage, accès, transfert, protection, responsabilités...), et de documenter les choix effectués.",
                    "resources": {},
                    "answer_items": {
                        "1.2.a": {
                            "order_id": "a",
                            "answer_text": "Informelle, basée sur la responsabilité et la compétence de chacun",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "1.2.b": {
                            "order_id": "b",
                            "answer_text": "Formalisée et accessible à tous les collaborateurs",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "1.2.c": {
                            "order_id": "c",
                            "answer_text": "Formalisée et maîtrisée par les collaborateurs",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "1.2.d": {
                            "order_id": "d",
                            "answer_text": "Formalisée, maîtrisée par les collaborateurs, documentée pour chaque traitement de données personnelles ou confidentielles",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        }
                    }
                },
                "element 3": {
                    "order_id": "3",
                    "name": "Veille réglementaire",
                    "condition": "n/a",
                    "question_text": "Un processus de veille réglementaire est-il mis en place, en interne ou via un prestataire spécialisé, pour connaître les évolutions applicables et impactantes pour votre organisation ?",
                    "question_type": "radio",
                    "answer_hint": "Sélectionner une seule réponse, correspondant le mieux au niveau de maturité de l'organisation sur ce sujet",
                    "explanation_text": "Au-delà de l'identification des réglementations et des approches de mise en conformité, il est important de mettre en place des processus de veille pour connaître et suivre **l'évolution** des réglementations applicables (qui peuvent être très spécifiques dans certains secteurs). Exemple(s) intéressant(s) : [Welfare surveillance system violates human rights, Dutch court rules](https://www.theguardian.com/technology/2020/feb/05/welfare-surveillance-system-violates-human-rights-dutch-court-rules).",
                    "resources": {},
                    "answer_items": {
                        "1.3.a": {
                            "order_id": "a",
                            "answer_text": "Nous ne faisons pas vraiment de veille réglementaire",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "1.3.b": {
                            "order_id": "b",
                            "answer_text": "Nous faisons une veille informelle, chaque collaborateur remonte les informations sur un moyen de communication dédiée",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "1.3.c": {
                            "order_id": "c",
                            "answer_text": "Nous avons une veille formalisée, les responsables sont identifiés, le processus est documenté",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        }
                    }
                },
                "element 4": {
                    "order_id": "4",
                    "name": "Législation et exigences contractuelles applicables - Audit et certification",
                    "condition": "n/a",
                    "question_text": "La conformité de l'organisation aux exigences relatives aux données personnelles et confidentielles a-t-elle été auditée et est-elle reconnue par une certification, un organisme tiers ou équivalent ?",
                    "question_type": "radio",
                    "answer_hint": "Sélectionner une seule réponse, correspondant le mieux au niveau de maturité de l'organisation sur ce sujet",
                    "explanation_text": "Dans de nombreux secteurs il existe des exigences de conformité spécifiques. Il est généralement possible de formaliser la conformité d'une organisation par une certification ou un audit spécialisé, l'obtention d'un label.",
                    "resources": {},
                    "answer_items": {
                        "1.4.a": {
                            "order_id": "a",
                            "answer_text": "Oui",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "1.4.b": {
                            "order_id": "b",
                            "answer_text": "Non",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        }
                    }
                },
                "element 5": {
                    "order_id": "5",
                    "name": "Principe de minimisation",
                    "condition": "n/a",
                    "question_text": "Dans le cadre des projets de data science, le principe de minimisation doit guider la collecte et l'utilisation de données personnelles ou confidentielles. Comment est-il mis en oeuvre au sein de votre organisation ?",
                    "question_type": "radio",
                    "answer_hint": "Sélectionner une seule réponse, correspondant le mieux au niveau de maturité de l'organisation sur ce sujet",
                    "explanation_text": "Le principe de minimisation est parfois aussi évoqué par l'expression *privacy by design*. Il est un des piliers du RGPD.",
                    "resources": {},
                    "answer_items": {
                        "1.5.a": {
                            "order_id": "a",
                            "answer_text": "Nous faisons en sorte de n'utiliser aucune données personnelles ou confidentielles. Nous ne sommes pas concernés par cet univers de risque",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "1.5.b": {
                            "order_id": "b",
                            "answer_text": "Nous avons besoin d'en utiliser dans certains projets et le principe de minimisation est alors systématiquement appliqué",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "1.5.c": {
                            "order_id": "c",
                            "answer_text": "Le principe de minimisation est connu des collaborateurs, qui l'appliquent en général",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "1.5.d": {
                            "order_id": "d",
                            "answer_text": "Le réflexe \"qui peut le plus peut le moins\" vis-à-vis des données existe encore ici et là au sein de notre organisation. Dans certains projets, nous conservons des jeux de données beaucoup plus riches en données personnelles et confidentielles que ce qui est strictement utile au projet",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        }
                    }
                },
                "element 6": {
                    "order_id": "6",
                    "name": "Projet impliquant un nouveau traitement de données personnelles ou confidentielles",
                    "condition": "1.5.a",
                    "question_text": "Pour chaque traitement de données personnelles ou confidentielles nécessaire dans le cadre d'un projet de data science, au sein de votre organisation :",
                    "question_type": "checkbox",
                    "answer_hint": "Sélectionner tous les éléments de réponse correspondant à des pratiques de votre organisation",
                    "explanation_text": "Le *Privacy Impact Assessment* (PIA) est une méthode d'évaluation de l'impact d'un traitement de données, proche des méthodes classiques d'évaluation des risques. Dans certains cas, par exemple lorsqu'un traitement présente des risques élevés pour les droits et libertés des personnes physiques, le RGPD rend obligatoire la réalisation d'un PIA avant la mise en oeuvre du traitement.",
                    "resources": {},
                    "answer_items": {
                        "1.6.a": {
                            "order_id": "a",
                            "answer_text": "Nous élaborons un *Privacy Impact Assessment* (PIA)",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "1.6.b": {
                            "order_id": "b",
                            "answer_text": "Nous mettons en oeuvre des mesures de protections (concernant notamment le transfert, le stockage, et l'accès aux données concernées)",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "1.6.c": {
                            "order_id": "c",
                            "answer_text": "Nous documentons les PIA et mesures mises en oeuvre et nous les conservons au sein des projets",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "1.6.d": {
                            "order_id": "d",
                            "answer_text": "Nous contractualisons les relations avec les fournisseurs et les clients et les responsabilités qui en découlent",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        }
                    }
                },
                "element 7": {
                    "order_id": "7",
                    "name": "Sécurité de l'apprentissage automatique et _PETs_ - Niveau de connaissance",
                    "condition": "1.5.a",
                    "question_text": "La sécurité de l'apprentissage automatique (_ML security_) est un domaine en plein développement. Dans certains cas de figure, les modèles prédictifs appris sur des données confidentielles peuvent révéler des éléments de ces données confidentielles. Au sein de votre organisation, au sujet des vulnérabilités liées aux modèles de ML et aux _Privacy Enhancing Technologies (PETs)_, le niveau de connaissance générale des collaborateurs intervenant sur les projets de data science est :",
                    "question_type": "radio",
                    "answer_hint": "Sélectionner une seule réponse, correspondant le mieux au niveau de maturité de l'organisation sur ce sujet",
                    "explanation_text": "L'état de l'art de la sécurité du ML est en constante évolution. S'il est impossible de se prémunir contre toutes les vulnérabilités à tout instant, il est crucial de s'en préoccuper et se tenir au courant. Le [OWASP Top Five ML risks](https://github.com/OWASP/Top-5-Machine-Learning-Risks/blob/master/Top%205%20Machine%20Learning%20Risks.md) est par exemple un point d'entrée intéressant.",
                    "resources": {
                        "0": {
                            "resource_type": "Web article",
                            "resource_text": "*[Top Five ML risks](https://github.com/OWASP/Top-5-Machine-Learning-Risks/blob/master/Top%205%20Machine%20Learning%20Risks.md)*, OWASP"
                        },
                        "1": {
                            "resource_type": "Web article",
                            "resource_text": "*[The secret-sharer: evaluating and testing unintended memorization in neural networks](https://blog.acolyer.org/2019/09/23/the-secret-sharer/)*, A. Colyer, 2019"
                        },
                        "2": {
                            "resource_type": "Academic paper",
                            "resource_text": "*[Membership Inference Attacks against Machine Learning Models](https://arxiv.org/abs/1610.05820)*, R. Shokri, M. Stronati, C. Song, V. Shmatikov, 2017"
                        },
                        "3": {
                            "resource_type": "Software & Tools",
                            "resource_text": "*[ML Privacy Meter](https://github.com/privacytrustlab/ml_privacy_meter): a tool to quantify the privacy risks of machine learning models with respect to inference attacks*"
                        },
                        "4": {
                            "resource_type": "Web article",
                            "resource_text": "*[Demystifying the membership inference attack](https://medium.com/disaitek/demystifying-the-membership-inference-attack-e33e510a0c39)*, Disaitek, 2019"
                        },
                        "5": {
                            "resource_type": "Academic paper",
                            "resource_text": "*[Inverting Gradients - How easy is it to break privacy in federated learning?](https://arxiv.org/abs/2003.14053)*, J. Geiping, H. Bauermeister, H. Dröge, M. Moeller, 2020"
                        },
                        "6": {
                            "resource_type": "Software & Tools",
                            "resource_text": "Outils pour la *differential privacy* : Google [differential privacy library](https://github.com/google/differential-privacy) et le wrapper Python [PyDP](https://github.com/OpenMined/PyDP) d'OpenMined, Facebook AI's [Opacus](https://github.com/pytorch/opacus) pour PyTorch"
                        },
                        "7": {
                            "resource_type": "Web article",
                            "resource_text": "La *distillation* d'un modèle, en plus de la compression qu'elle apporte, peut être utilisée comme une mesure de protection du modèle et des données d'entraînement utilisées, voir par exemple *[Knowledge Distillation : Simplified](https://towardsdatascience.com/knowledge-distillation-simplified-dd4973dbc764)*, Towards Data Science, 2019"
                        },
                        "8": {
                            "resource_type": "Academic paper",
                            "resource_text": "*[Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531)*, G. Hinton, O. Vinyals, J. Dean, 2015"
                        }
                    },
                    "answer_items": {
                        "1.7.a": {
                            "order_id": "a",
                            "answer_text": "Débutant",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "1.7.b": {
                            "order_id": "b",
                            "answer_text": "Intermédiaire",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "1.7.c": {
                            "order_id": "c",
                            "answer_text": "Confirmé",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "1.7.d": {
                            "order_id": "d",
                            "answer_text": "Expert",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        }
                    }
                },
                "element 8": {
                    "order_id": "8",
                    "name": "Sécurité de l'apprentissage automatique et _PETs_ - Mise en oeuvre",
                    "condition": "1.5.a",
                    "question_text": "Toujours au sujet des vulnérabilités liées aux modèles de ML et aux _PETs_ :",
                    "question_type": "checkbox",
                    "answer_hint": "Sélectionner tous les éléments de réponse correspondant à des pratiques de votre organisation",
                    "explanation_text": "L'état de l'art de la sécurité du ML est en constante évolution. S'il est impossible de se prémunir contre toutes les vulnérabilités à tout instant, il est crucial de s'en préoccuper et d'organiser une veille. Le [OWASP Top Five ML risks](https://github.com/OWASP/Top-5-Machine-Learning-Risks/blob/master/Top%205%20Machine%20Learning%20Risks.md) est par exemple un point d'entrée intéressant.\n\nSelon les niveaux de risque et de sensibilité des projets, certaines approches *PETs* seront sélectionnées et implémentées. Il est important de suivre l'évolution de l'état de l'art et des pratiques, et de documenter les choix réalisés. On introduit ici la notion de \"généalogie de bout-en-bout\".",
                    "resources": {
                        "0": {
                            "resource_type": "Web article",
                            "resource_text": "*[Top Five ML risks](https://github.com/OWASP/Top-5-Machine-Learning-Risks/blob/master/Top%205%20Machine%20Learning%20Risks.md)*, OWASP"
                        },
                        "1": {
                            "resource_type": "Web article",
                            "resource_text": "*[The secret-sharer: evaluating and testing unintended memorization in neural networks](https://blog.acolyer.org/2019/09/23/the-secret-sharer/)*, A. Colyer, 2019"
                        },
                        "2": {
                            "resource_type": "Academic paper",
                            "resource_text": "*[Membership Inference Attacks against Machine Learning Models](https://arxiv.org/abs/1610.05820)*, R. Shokri, M. Stronati, C. Song, V. Shmatikov, 2017"
                        },
                        "3": {
                            "resource_type": "Software & Tools",
                            "resource_text": "*[ML Privacy Meter](https://github.com/privacytrustlab/ml_privacy_meter): a tool to quantify the privacy risks of machine learning models with respect to inference attacks*"
                        },
                        "4": {
                            "resource_type": "Web article",
                            "resource_text": "*[Demystifying the membership inference attack](https://medium.com/disaitek/demystifying-the-membership-inference-attack-e33e510a0c39)*, Disaitek, 2019"
                        },
                        "5": {
                            "resource_type": "Academic paper",
                            "resource_text": "*[Inverting Gradients - How easy is it to break privacy in federated learning?](https://arxiv.org/abs/2003.14053)*, J. Geiping, H. Bauermeister, H. Dröge, M. Moeller, 2020"
                        },
                        "6": {
                            "resource_type": "Software & Tools",
                            "resource_text": "Outils pour la *differential privacy* : Google *[differential privacy library](https://github.com/google/differential-privacy)*, et le wrapper Python [PyDP](https://github.com/OpenMined/PyDP) d'OpenMined"
                        },
                        "7": {
                            "resource_type": "Web article",
                            "resource_text": "La *distillation* d'un modèle, en plus de la compression qu'elle apporte, peut être utilisée comme une mesure de protection du modèle et des données d'entraînement utilisées, voir par exemple *[Knowledge Distillation: Simplified](https://towardsdatascience.com/knowledge-distillation-simplified-dd4973dbc764)*, Towards Data Science, 2019"
                        },
                        "8": {
                            "resource_type": "Academic paper",
                            "resource_text": "*[Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531)*, G. Hinton, O. Vinyals, J. Dean, 2015"
                        }
                    },
                    "answer_items": {
                        "1.8.a": {
                            "order_id": "a",
                            "answer_text": "Une veille technique est mise en oeuvre",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "1.8.b": {
                            "order_id": "b",
                            "answer_text": "Les collaborateurs reçoivent régulièrement des informations / formations qui leur permettent de monter en compétences",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "1.8.c": {
                            "order_id": "c",
                            "answer_text": "Dans certains projets, nous mettons en oeuvre des _PETs_ permettant de réduire les risques liés aux modèles que nous élaborons",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "1.8.d": {
                            "order_id": "d",
                            "answer_text": "Sur chaque projet, les vulnérabilités qui s'y appliquent et les *PETs* mises en oeuvre sont documentées dans la généalogie de bout-en-bout de chaque modèle",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        }
                    }
                },
                "element 9": {
                    "order_id": "9",
                    "name": "Notifications d’incidents de sécurité aux autorités de régulation",
                    "condition": "1.5.a",
                    "question_text": "Dans le cas de figure où un modèle que l'organisation a élaboré est utilisé ou accessible par une(des) partie(s) prenante(s) externe(s), et qu'une vulnérabilité nouvelle est publiée, présente un risque de s'y appliquer et crée ainsi un risque d'exposition de données personnelles ou confidentielles :",
                    "question_type": "checkbox",
                    "answer_hint": "Sélectionner tous les éléments de réponse correspondant à des pratiques de votre organisation",
                    "explanation_text": "Il existe dans certains secteurs des obligations de signalement des incidents de sécurité aux autorités de régulation (e.g. CNIL, ANSSI, ARS...). Un point d'entrée intéressant : [Notifications d’incidents de sécurité aux autorités de régulation : comment s’organiser et à qui s’adresser ?](https://www.cnil.fr/fr/notifications-dincidents-de-securite-aux-autorites-de-regulation-comment-sorganiser-et-qui-sadresser) sur le site de la CNIL.",
                    "resources": {},
                    "answer_items": {
                        "1.9.a": {
                            "order_id": "a",
                            "answer_text": "Nous avons une procédure décrivant la marche à suivre",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "1.9.b": {
                            "order_id": "b",
                            "answer_text": "Notre procédure inclut une communication aux parties prenantes en question",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "1.9.c": {
                            "order_id": "c",
                            "answer_text": "Notre procédure référence les autorités auxquelles nous devons faire un signalement",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        }
                    }
                }
            }
        },
        "section 2": {
            "order_id": "2",
            "name": "Prévenir les biais, élaborer des modèles non discriminatoires",
            "description": "L'utilisation de modèles prédictifs élaborés à partir de données historiques peut se révéler contre-productive lorsque les données historiques sont contaminées par des phénomènes problématiques (e.g. qualité de certains points de données, données non comparables, phénomène social non souhaitable du fait de l'époque...). Il apparaît indispensable de s'interroger sur ce risque et d'étudier la nature des données utilisées, les conditions dans lesquelles elles ont été produites et assembées, et ce qu'elles représentent.\nDans certains cas, une spécification de l'équité recherchée entre populations doit également être définie. L'équité d'un modèle peut [être définie de plusieurs manières qui peuvent être incompatibles entre elles](https://papers.nips.cc/paper/6995-counterfactual-fairness), et l'interprétation de scores de performances doit donc se faire dans le cadre de l'une de ces définitions.",
            "elements": {
                "element 1": {
                    "order_id": "1",
                    "name": "Analyse des données d'entraînement utilisées",
                    "condition": "n/a",
                    "question_text": "Au sein des projets de data science et lors de l'élaboration de jeux de données d'entraînement, un travail de réflexion et recherche de phénomènes intempestifs ou parasites du fait de l'époque, du contexte, des outils ou processus d'enregistrement peut s'avérer crucial pour prévenir des biais portant atteinte au principe de non-discrimination, de diversité et d'équité. Votre organisation :",
                    "question_type": "radio",
                    "answer_hint": "Sélectionner une seule réponse, correspondant le mieux au niveau de maturité de l'organisation sur ce sujet",
                    "explanation_text": "Il s'agit de s'obliger à s'interroger sur ces sujets et donc à réfléchir aux données utilisées, la manière dont elles ont été produites etc.",
                    "resources": {
                        "0": {
                            "resource_type": "Web article",
                            "resource_text": "*[Hidden Bias](https://pair.withgoogle.com/explorables/hidden-bias/)* explorable from [PAIR](https://pair.withgoogle.com/)"
                        },
                        "1": {
                            "resource_type": "Technical guide",
                            "resource_text": "*[Tour of Data Sampling Methods for Imbalanced Classification](https://machinelearningmastery.com/data-sampling-methods-for-imbalanced-classification/)*"
                        }
                    },
                    "answer_items": {
                        "2.1.a": {
                            "order_id": "a",
                            "answer_text": "Fonctionne de manière informelle à ce sujet et s'appuie sur la compétence et la responsabilité des collaborateurs impliquées",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "2.1.b": {
                            "order_id": "b",
                            "answer_text": "Dispose d'une approche documentée et systématiquement mise en oeuvre",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        }
                    }
                },
                "element 2": {
                    "order_id": "2",
                    "name": "Risques de discrimination à l'encontre de certains groupes sociaux",
                    "condition": "n/a",
                    "question_text": "Votre organisation est-elle concernée par des cas de figure où des modèles prédictifs sont utilisés dans des environnements thématiques pour lesquels des risques de discrimination à l'encontre de certains groupes sociaux (genre, origine, âge, etc.) existent ?",
                    "question_type": "radio",
                    "answer_hint": "Sélectionner une seule réponse, correspondant le mieux au niveau de maturité de l'organisation sur ce sujet",
                    "explanation_text": "n/a",
                    "resources": {},
                    "answer_items": {
                        "2.2.a": {
                            "order_id": "a",
                            "answer_text": "Concerné",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "2.2.b": {
                            "order_id": "b",
                            "answer_text": "Non concerné",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        }
                    }
                },
                "element 3": {
                    "order_id": "3",
                    "name": "Prévention des biais discriminatoires",
                    "condition": "2.2.b",
                    "question_text": "Dans les cas de figure où les modèles prédictifs que votre organisation élabore sont utilisés dans des environnements thématiques où il y a des risques de discrimination à l'encontre de certains groupes sociaux (genre, origine, âge, etc.) :",
                    "question_type": "checkbox",
                    "answer_hint": "Sélectionner tous les éléments de réponse correspondant à des pratiques de votre organisation",
                    "explanation_text": "Il s'agit de s'interroger systématiquement, à chaque projet de data science et selon l'objectif et l'usage cible du modèle que l'on veut élaborer, sur les features pouvant directement ou indirectement être à l'origine d'un risque de biais discriminatoire.\nComplément sur l'utilisation de données synthétiques et d'approches de _data augmentation_, _re-weighting_ : lorsque de telles techniques sont utilisées il est important de les expliciter, au risque sinon de perdre de l'information sur la manière dont un modèle a été élaboré.",
                    "resources": {
                        "0": {
                            "resource_type": "Web article",
                            "resource_text": "[Awful AI](https://github.com/daviddao/awful-ai), un registre des services ou projets d'IA inquiétants, David Dao"
                        },
                        "1": {
                            "resource_type": "Web article",
                            "resource_text": "*[Measuring fairness](https://pair.withgoogle.com/explorables/measuring-fairness)* explorable, [PAIR](https://pair.withgoogle.com/)"
                        },
                        "2": {
                            "resource_type": "Software & Tools",
                            "resource_text": "*[AI Fairness 360](https://developer.ibm.com/technologies/artificial-intelligence/projects/ai-fairness-360/): an open source software toolkit that can help detect and remove bias in machine learning models*, IBM"
                        },
                        "3": {
                            "resource_type": "Academic paper",
                            "resource_text": "*Fairness metrics* : *[counterfactual fairness](https://papers.nips.cc/paper/6995-counterfactual-fairness)*"
                        },
                        "4": {
                            "resource_type": "Academic paper",
                            "resource_text": "*Fairness metrics* : *[adversarial debiaising](https://arxiv.org/pdf/1801.07593.pdf)*"
                        }
                    },
                    "answer_items": {
                        "2.3.a": {
                            "order_id": "a",
                            "answer_text": "Nous portons une attention particulière à l'identification de variables protégées et à leurs proxys éventuels",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "2.3.b": {
                            "order_id": "b",
                            "answer_text": "Nous procédons à des évaluations sur des données de test comprenant différentes sous-populations afin d'identifier les éventuels biais problématiques",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "2.3.c": {
                            "order_id": "c",
                            "answer_text": "Nous sélectionnons et mettons en oeuvre une ou plusieurs mesure(s) de justice et d'équité (_fairness metric_)",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "2.3.d": {
                            "order_id": "d",
                            "answer_text": "Nous mettons en oeuvre des approches de type _data augmentation_ ou _re-weighting_",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "2.3.e": {
                            "order_id": "e",
                            "answer_text": "Les pratiques ci-dessus que nous mettons en oeuvre sont dûment documentées et intégrées à la généalogie de bout-en-bout des modèles concernés",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        }
                    }
                }
            }
        },
        "section 3": {
            "order_id": "3",
            "name": "Evaluer la performance de manière rigoureuse et expliquer les prédictions",
            "description": "Le score de performance d'un modèle prédictif est déterminant pour son adoption dans des produits, systèmes ou processus. L'évaluation de la performance se doit donc d'être rigoureuse. Par ailleurs un modèle prédictif peut-être utilisé comme un système automatique, dont les règles de fonctionnement ne sont pas écrites _in extenso_ et ne se prêtent pas ou mal à être explicitées, débattues, ajustées. Des efforts sont donc nécessaires sur l'interprétation et l'explication des choix réalisés à l'aide de ces systèmes.",
            "elements": {
                "element 1": {
                    "order_id": "1",
                    "name": "Séparation des jeux de données de test",
                    "condition": "n/a",
                    "question_text": "Au sein des projets de data science et lors de l'élaboration de jeux de données de test, il est capital d'assurer la non-contamination par des données d'entraînement. Votre organisation :",
                    "question_type": "checkbox",
                    "answer_hint": "Sélectionner tous les éléments de réponse correspondant à des pratiques de votre organisation. Attention, certaines combinaisons ne seraient pas cohérentes",
                    "explanation_text": "Assurer l'étanchéité des jeux de données d'entraînement et de test est un principe connu et maîtrisé par la plupart des organisations. Il peut se révéler délicats dans certaines configurations particulières (e.g. apprentissage continu, apprentissage distribué *privacy-preserving*...).",
                    "resources": {},
                    "answer_items": {
                        "3.1.a": {
                            "order_id": "a",
                            "answer_text": "Fonctionne de manière informelle à ce sujet et s'appuie sur la compétence et la responsabilité des collaborateurs impliquées",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "3.1.b": {
                            "order_id": "b",
                            "answer_text": "Dispose d'une approche documentée et systématiquement mise en oeuvre d'isolation des testsets",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "3.1.c": {
                            "order_id": "c",
                            "answer_text": "Utilise un outil de versionnage et de traçabilité des jeux de données d'entraînement et de test utilisés, permettant ainsi de vérifier ou auditer ultérieurement la non-contamination des données de tests",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "3.1.d": {
                            "order_id": "d",
                            "answer_text": "Prévoit systématiquement l'élaboration de deux testsets ou plus pour gagner en résilience",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        }
                    }
                },
                "element 2": {
                    "order_id": "2",
                    "name": "Projets d'apprentissage distribué préservant la confidentialité",
                    "condition": "n/a",
                    "question_text": "Dans les cas de figure de projets de data science basé sur l'apprentissage distribué ou fédéré (*distributed learning* ou *federated learning*) sur des jeux de données multiples et dont la confidentialité doit être préservée vis-à-vis des autres (*privacy-preserving*) :",
                    "question_type": "radio",
                    "answer_hint": "Sélectionner une seule réponse, correspondant le mieux au niveau de maturité de l'organisation sur ce sujet",
                    "explanation_text": "Dans ce type de projet d'apprentissage distribué dans des conditions où les données sont maintenues confidentielles, se pose la question de comment composer un jeu de données de test en s'assurant que celles-ci ne figurent pas aussi dans le jeu de données d'entraînement (par exemple chez un autre partenaire).",
                    "resources": {},
                    "answer_items": {
                        "3.2.a": {
                            "order_id": "a",
                            "answer_text": "Nous ne participons pas à des projets d'apprentissage distribué *privacy-preserving*",
                            "is_concerned_switch": 1,
                            "depends_on": ""
                        },
                        "3.2.b": {
                            "order_id": "b",
                            "answer_text": "Nous maîtrisons et mettons en oeuvre des approches permettant d'élaborer des jeux de données de test de manière à ce qu'il n'y ait pas de contamination croisée entre données d'entraînement et de test provenant des différents partenaires",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        },
                        "3.2.c": {
                            "order_id": "c",
                            "answer_text": "À ce stade nous ne maîtrisons pas les méthodes permettant d'élaborer des jeux de données de test de manière à ce qu'il n'y ait pas de contamination croisée entre données d'entraînement et de test provenant des différents partenaires",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        }
                    }
                },
                "element 3": {
                    "order_id": "3",
                    "name": "Analyse des données de test",
                    "condition": "n/a",
                    "question_text": "Au sein des projets de data science et lors de l'élaboration de jeux de données de test, un travail de réflexion et recherche de phénomènes intempestifs ou parasites du fait de l'époque, du contexte, des outils ou processus d'enregistrement peut s'avérer crucial pour la signification des scores de performance. Votre organisation :",
                    "question_type": "radio",
                    "answer_hint": "Sélectionner une seule réponse, correspondant le mieux au niveau de maturité de l'organisation sur ce sujet",
                    "explanation_text": "L'utilisation de modèles prédictifs testés sur des données historiques peut se révéler contre-productive lorsque les données historiques en question sont contaminées par des phénomènes problématiques (e.g. qualité de certains points de données, données non comparables, phénomène social non souhaitable du fait de l'époque...). Il apparaît indispensable de s'interroger sur ce risque et d'étudier la nature des données utilisées, les conditions dans lesquelles elles ont été produites et assemblées, et ce qu'elles représentent.",
                    "resources": {},
                    "answer_items": {
                        "3.3.a": {
                            "order_id": "a",
                            "answer_text": "Fonctionne de manière informelle à ce sujet et s'appuie sur la compétence et la responsabilité des collaborateurs impliquées",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "3.3.b": {
                            "order_id": "b",
                            "answer_text": "Dispose d'une approche documentée et systématiquement mise en oeuvre",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        }
                    }
                },
                "element 4": {
                    "order_id": "4",
                    "name": "Validation des performances",
                    "condition": "n/a",
                    "question_text": "Votre organisation met-elle en oeuvre les approches suivantes :",
                    "question_type": "checkbox",
                    "answer_hint": "Sélectionner tous les éléments de réponse correspondant à des pratiques de votre organisation",
                    "explanation_text": "Voir par exemple le *[p-hacking / data dredging](https://fr.wikipedia.org/wiki/Data_dredging)*.",
                    "resources": {
                        "0": {
                            "resource_type": "Academic paper",
                            "resource_text": "*Robustness metrics* : *[noise sensitivity score](https://arxiv.org/abs/1806.01477)*."
                        },
                        "1": {
                            "resource_type": "Technical guide",
                            "resource_text": "*[Adversarial Robustness - Theory and Practice](https://adversarial-ml-tutorial.org/)*, Z. Kolter et A. Madry"
                        }
                    },
                    "answer_items": {
                        "3.4.a": {
                            "order_id": "a",
                            "answer_text": "Lors de l'élaboration d'un modèle, nous choisissons la ou les métrique(s) de performance en amont de l'apprentissage automatique, parmi les métriques les plus standards possibles",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "3.4.b": {
                            "order_id": "b",
                            "answer_text": "La mise en oeuvre de mesures de robustesse (*robustness metrics*) est considérée et évaluée pour chaque projet d'élaboration d'un modèle, et appliquée par défaut dans les cas de figure où les données d'entrées peuvent être soumises à des perturbations fines (e.g. images, sons)",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "3.4.c": {
                            "order_id": "c",
                            "answer_text": "Les pratiques ci-dessus que nous mettons en oeuvre sont dûment documentées intégrées à la généalogie de bout-en-bout des modèles concernés, y compris les métriques de performance choisies",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        }
                    }
                },
                "element 5": {
                    "order_id": "5",
                    "name": "Suivi de la performance dans le temps",
                    "condition": "n/a",
                    "question_text": "Dans les cas de figure où des modèles prédictifs élaborés par votre organisation sont utilisés dans des systèmes en production :",
                    "question_type": "checkbox",
                    "answer_hint": "Sélectionner tous les éléments de réponse correspondant à des pratiques de votre organisation. Attention, certaines combinaisons ne seraient pas cohérentes",
                    "explanation_text": "Même sur un modèle stable il existe un risque que les données d'entrée ne soient plus dans le domaine au bout d'un certain temps (population & distribution), exemple : une variable qui ne serait plus renseignée à la même fréquence qu'avant par les utilisateurs dans un SI. Il est donc nécessaire de contrôler régulièrement la performance d'un modèle utilisé dans son contexte d'utilisation.\nSuivre l'évolution de la performance des modèles dans le temps est également particulièrement important dans les cas de figure d'apprentissage continu, présentant un risque de dégénérescence des modèles.",
                    "resources": {
                        "0": {
                            "resource_type": "Technical guide",
                            "resource_text": "*[Continuous delivery for machine learning](https://martinfowler.com/articles/cd4ml.html)*, D. Sato, A. Wider, C. Windheuser, Septembre 2019"
                        },
                        "1": {
                            "resource_type": "Technical guide",
                            "resource_text": "*[Monitoring Machine Learning Models in Production - A comprehensive guide](https://christophergs.com/machine%20learning/2020/03/14/how-to-monitor-machine-learning-models/)*, Christopher Samiullah, Mars 2020"
                        },
                        "2": {
                            "resource_type": "Web article",
                            "resource_text": "*[Google’s medical AI was super accurate in a lab. Real life was a different story](https://www.technologyreview.com/2020/04/27/1000658/google-medical-ai-accurate-lab-real-life-clinic-covid-diabetes-retina-disease/)*, MIT Technology Review"
                        }
                    },
                    "answer_items": {
                        "3.5.a": {
                            "order_id": "a",
                            "answer_text": "Les modèles que nous élaborons ne sont pas utilisés dans des systèmes en production",
                            "is_concerned_switch": 1,
                            "depends_on": ""
                        },
                        "3.5.b": {
                            "order_id": "b",
                            "answer_text": "La performance est systématiquement ré-évaluée lorsque le modèle est mis à jour",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        },
                        "3.5.c": {
                            "order_id": "c",
                            "answer_text": "La performance est systématiquement ré-évaluée lorsque le contexte d'utilisation du modèle évolue, ce qui peut créer un risque sur la performance du modèle du fait de l'évolution de l'espace des données d'entrée",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        },
                        "3.5.d": {
                            "order_id": "d",
                            "answer_text": "La distribution des données d'entrée est monitorée, et la performance est ré-évaluée régulièrement sur des données de test actualisées",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        },
                        "3.5.e": {
                            "order_id": "e",
                            "answer_text": "Des contrôles aléatoires sont réalisés sur des prédictions afin d'en contrôler la cohérence",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        }
                    }
                },
                "element 6": {
                    "order_id": "6",
                    "name": "Seuils de décision et plages d'indécision",
                    "condition": "n/a",
                    "question_text": "Lors de l'élaboration d'un modèle de classification, pour la définition des seuils de décision, votre organisation :",
                    "question_type": "checkbox",
                    "answer_hint": "Sélectionner tous les éléments de réponse correspondant à des pratiques de votre organisation. Attention, certaines combinaisons ne seraient pas cohérentes",
                    "explanation_text": "L'étude et à la sélection de seuils de décisions pertinents pour un problème de data science donné (*threshold selection*) est lié aux métriques retenues. Comme le présente l'article indiqué dans les ressources de cet élément d'évaluation, il peut être intéressant dans certains cas de considérer la possibilité de définir des plages d'indécision.",
                    "resources": {
                        "0": {
                            "resource_type": "Web article",
                            "resource_text": "*[Opening the algorithm’s black box and understand its outputs](https://medium.com/@asaboni/opening-the-algorithms-black-box-and-understand-its-outputs-e2363b0a887c)*, A. Saboni (Octo Technologies), April 2020"
                        }
                    },
                    "answer_items": {
                        "3.6.a": {
                            "order_id": "a",
                            "answer_text": "Fonctionne de manière informelle à ce sujet et s'appuie sur la compétence et la responsabilité des collaborateurs impliquées",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "3.6.b": {
                            "order_id": "b",
                            "answer_text": "Dispose d'une approche documentée et systématiquement mise en oeuvre",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "3.6.c": {
                            "order_id": "c",
                            "answer_text": "Dispose d'une approche documentée et systématiquement mise en oeuvre, qui inclut la possibilité de maintenir des plages d'indécision",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "3.6.d": {
                            "order_id": "d",
                            "answer_text": "Les choix réalisés pour chaque modèle et mis en oeuvre sont dûment documentées intégrées à la généalogie de bout-en-bout des modèles concernés",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        }
                    }
                },
                "element 7": {
                    "order_id": "7",
                    "name": "Audits par des tierces parties indépendantes et *verifiable claims*",
                    "condition": "n/a",
                    "question_text": "Lorsque votre organisation communique sur les résultats ou la performance d'un système d'IA, et s'appuie sur de telles communications pour son développement et vis-à-vis de ses parties prenantes :",
                    "question_type": "radio",
                    "answer_hint": "Sélectionner une seule réponse, correspondant le mieux au niveau de maturité de l'organisation sur ce sujet",
                    "explanation_text": "L'élaboration d'un modèle prédictif, et la détermination d'une mesure de performance de référence, signifiante et fiable, sont des défis complexes. Il est donc souvent délicat pour une organisation d'affirmer l'obtention d'excellents résultats et de s'en prévaloir avec certitude. Et lorsque cela est toutefois possible, il peut être plus délicat encore de mettre à disposition publiquement des éléments de preuve sans avoir à révéler d'information précieuse composant la propriété intellectuelle de l'organisation et la valeur même des travaux réalisés. Dans ces cas de figure, il est recommandé de faire procéder à un audit par une tierce partie indépendante (e.g. sécurité, privacy, fairness, fiabilité...), afin de sécuriser les résultats dont l'organisation souhaite se prévaloir.",
                    "resources": {
                        "0": {
                            "resource_type": "Academic paper",
                            "resource_text": "[Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable Claims](https://arxiv.org/pdf/2004.07213.pdf), §2 p.8-20, Avril 2020"
                        }
                    },
                    "answer_items": {
                        "3.7.a": {
                            "order_id": "a",
                            "answer_text": "Nous ne communiquons pas et n'utilisons pas les résultats ou la performance de nos systèmes d'IA comme argument vis-à-vis de nos parties prenantes, nous ne sommes pas concernés par cet élément d'évaluation",
                            "is_concerned_switch": 1,
                            "depends_on": ""
                        },
                        "3.7.b": {
                            "order_id": "b",
                            "answer_text": "Nous communiquons sur nos résultats et nous appuyons sur ceux-ci pour notre développement sans faire auditer auparavant nos travaux par une tierce partie indépendante, sans mettre à disposition d'éléments de preuve",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        },
                        "3.7.c": {
                            "order_id": "c",
                            "answer_text": "Nous faisons auditer nos travaux par une tierce partie indépendante, ou nous mettons à disposition des éléments de preuve, avant de communiquer sur nos résultats et de nous en prévaloir vis-à-vis de nos parties prenantes",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        }
                    }
                },
                "element 8": {
                    "order_id": "8",
                    "name": "Explicabilité et interprétabilité",
                    "condition": "n/a",
                    "question_text": "Au sein des projets de data science qui visent à élaborer des modèles prédictifs :",
                    "question_type": "checkbox",
                    "answer_hint": "Sélectionner tous les éléments de réponse correspondant à des pratiques de votre organisation. Attention, certaines combinaisons ne seraient pas cohérentes",
                    "explanation_text": "L'explicabilité et l'interprétabilité sont des enjeux-clés, en lien avec les exigences croissantes de transparence, d'impartialité et de responsabilité. Dans certains cas, la réglementation impose même de pouvoir expliquer aux personnes concernées comment fonctionne un algorithme.\nDes ressources techniques comme SHAP ou LIME permettent d'entrer de plain-pied dans le sujet (voir les ressources associées à cet élément d'évaluation).",
                    "resources": {
                        "0": {
                            "resource_type": "Web article",
                            "resource_text": "*[La confiance des utilisateurs dans les systèmes impliquant de l’Intelligence Artificielle](https://blog.octo.com/la-confiance-des-utilisateurs-dans-les-systemes-impliquant-de-lintelligence-artificielle/)*, Blog Octo Technologies, Octobre 2019"
                        },
                        "1": {
                            "resource_type": "Technical guide",
                            "resource_text": "*[Interpretable Machine Learning, A Guide for Making Black Box Models Explainable](https://christophm.github.io/interpretable-ml-book/)*, Christoph Molnar"
                        },
                        "2": {
                            "resource_type": "Web article",
                            "resource_text": "*[Understanding model predictions with LIME](https://towardsdatascience.com/understanding-model-predictions-with-lime-a582fdff3a3b)*, blog L. Hulstaert, 2018"
                        },
                        "3": {
                            "resource_type": "Software & Tools",
                            "resource_text": "*[SHAP](https://github.com/slundberg/shap): A game theoretic approach to explain the output of any machine learning model*"
                        },
                        "4": {
                            "resource_type": "Web article",
                            "resource_text": "Dans certains cas la réglementation impose de pouvoir expliquer aux personnes concernées comment fonctionne un algorithme (voir par exemple [l'article 22 du RGPD](https://www.cnil.fr/fr/reglement-europeen-protection-donnees/chapitre3#Article22), [l'article 10 de la loi Informatique et libertés](https://www.legifrance.gouv.fr/affichTexteArticle.do;?idArticle=LEGIARTI000037090394&cidTexte=LEGITEXT000006068624&dateTexte=20180624), cités notamment dans le [Serment d'Hippocrate pour data scientist](https://hippocrate.tech/))"
                        }
                    },
                    "answer_items": {
                        "3.8.a": {
                            "order_id": "a",
                            "answer_text": "Notre organisation n'est pour l'instant pas familière avec les méthodes et outils d'explicabilité et d'interprétabilité des modèles",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "3.8.b": {
                            "order_id": "b",
                            "answer_text": "Nous nous intéressons au sujet de l'explicabilité et l'interprétabilité des modèles et dialoguons avec nos parties prenantes sur ce sujet",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "3.8.c": {
                            "order_id": "c",
                            "answer_text": "Nous faisons en sorte que les modèles que nous élaborons fournissent lorsque cela est pertinent a minima un niveau de confiance avec chaque prédiction réalisée",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "3.8.d": {
                            "order_id": "d",
                            "answer_text": "Nous déterminons le meilleur compromis entre la performance et l'interprétabilité pour chaque modèle que nous élaborons, ce qui nous amène parfois à opter pour un modèle plus simple à expliquer aux personnes concernées (un modèle performant permettra de diminuer les risques d’erreur tandis qu’un modèle interprétable permettra de mieux justifier les résultats du modèle)",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "3.8.e": {
                            "order_id": "e",
                            "answer_text": "Nous maîtrisons et mettons en oeuvre des approches avancées pour l'explicabilité et l'interprétabilité des modèles",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        }
                    }
                }
            }
        },
        "section 4": {
            "order_id": "4",
            "name": "Assurer la reproductibilité des modèles et en établir la chaîne de responsabilité",
            "description": "Un modèle prédictif est un objet informatique complexe qui peut évoluer au fil des apprentissages. Tracer les étapes de son élaboration et de son évolution permet d'en constituer une forme de **généalogie**, pré-requis pour **reproduire ou auditer** un modèle. Par ailleurs utiliser des systèmes automatiques basés sur des modèles dont les règles ont été \"apprises\" (et non définies et formalisées) interroge le fonctionnement des organisations. Il apparaît indispensable de garantir une chaîne de responsabilité claire, de personnes physiques ou morales, pour chaque modèle.",
            "elements": {
                "element 1": {
                    "order_id": "1",
                    "name": "\"Généalogie de bout-en-bout\" des modèles",
                    "condition": "n/a",
                    "question_text": "Tracer les étapes de l'élaboration d'un modèle permet d'en constituer une forme de **généalogie**. Au sein de votre organisation, une généalogie de bout-en-bout des modèles est alimentée et tenue à jour dans le cadre des projets de data science, tout au long des phase de collecte de données, conception, entraînement, validation et exploitation des modèles :",
                    "question_type": "radio",
                    "answer_hint": "Sélectionner une seule réponse, correspondant le mieux au niveau de maturité de l'organisation sur ce sujet",
                    "explanation_text": "Ce concept de \"généalogie de bout-en-bout\" d'un modèle prédictif appris peut se décliner sous la forme par exemple d'un document de référence reprenant tous les choix importants ainsi que tout l'historique d'élaboration du modèle (données utilisées, pré-traitements réalisés, type d'apprentissage et architecture du modèle, seuils de décision, métriques de tests...), etc.), et de processus internes organisant cette activité. En particulier, il est intéressant d'y faire figurer les choix de compromis (*trade-offs*) qui ont été faits et pourquoi (e.g. trade-offs précision-spécificité, performance-privacy, performance-coût computationnel, etc.).",
                    "resources": {
                        "0": {
                            "resource_type": "Software & Tools",
                            "resource_text": "[Substra Framework](http://doc.substra.ai/): *an open source framework offering distributed orchestration of machine learning tasks among partners while guaranteeing secure and trustless traceability of all operations*"
                        },
                        "1": {
                            "resource_type": "Software & Tools",
                            "resource_text": "[MLflow](https://mlflow.org/): *an open source platform to manage the ML lifecycle, including experimentation, reproducibility, deployment, and a central model registry*"
                        },
                        "2": {
                            "resource_type": "Software & Tools",
                            "resource_text": "[DVC](https://dvc.org/): *an Open-source Version Control System for Machine Learning Projects*"
                        },
                        "3": {
                            "resource_type": "Software & Tools",
                            "resource_text": "[DAGsHub](https://dagshub.com/docs/): *a platform for data version control and collaboration, based on DVC*"
                        }
                    },
                    "answer_items": {
                        "4.1.a": {
                            "order_id": "a",
                            "answer_text": "À ce stade nous n'avons pas mis en oeuvre d'approche de ce type",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "4.1.b": {
                            "order_id": "b",
                            "answer_text": "Ces informations existent et sont enregistrées afin de ne pas être perdues, mais elles peuvent l'être de manière désordonnée et ne sont pas versionnées",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "4.1.c": {
                            "order_id": "c",
                            "answer_text": "Elles sont rassemblées en un unique document qui accompagne systématiquement le modèle",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "4.1.d": {
                            "order_id": "d",
                            "answer_text": "Elles sont rassemblées en un unique document qui accompagne systématiquement le modèle et versionnées",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        }
                    }
                },
                "element 2": {
                    "order_id": "2",
                    "name": "Conditions et limites d'utilisation d'un modèle",
                    "condition": "n/a",
                    "question_text": "Dans le cadre des projets de data science, les \"conditions et limites de validité\" d'un modèle conçu, entraîné et validé par l'organisation :",
                    "question_type": "checkbox",
                    "answer_hint": "Sélectionner tous les éléments de réponse correspondant à des pratiques de votre organisation. Attention, certaines combinaisons ne seraient pas cohérentes",
                    "explanation_text": "Il s'agit d'expliciter et d'adjoindre au modèle la description du contexte d'utilisation pour lequel il a été conçu et dans lequel sa performance annoncée est significative. Ce concept de \"conditions et limites de validité\" peut se décliner sous la forme d'un document synthétique ou d'une section spécifique dans la \"généalogie de bout-en-bout\".",
                    "resources": {
                        "0": {
                            "resource_type": "Web article",
                            "resource_text": "[Model Cards](https://modelcards.withgoogle.com/about) de Google est un framework ouvert et évolutif, et propose 2 exemples : *To explore the possibilities of model cards in the real world, we've designed examples for two features of our Cloud Vision API, Face Detection and Object Detection. They provide simple overviews of both models' ideal forms of input, visualize some of their key limitations, and present basic performance metrics.*"
                        }
                    },
                    "answer_items": {
                        "4.2.a": {
                            "order_id": "a",
                            "answer_text": "Ne sont pas documentées",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "4.2.b": {
                            "order_id": "b",
                            "answer_text": "Sont explicitées et documentées",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "4.2.c": {
                            "order_id": "c",
                            "answer_text": "Sont versionnées",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "4.2.d": {
                            "order_id": "d",
                            "answer_text": "Contiennent une description des risques que présenterait une utilisation en dehors des \"conditions et limites de validité\"",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "4.2.e": {
                            "order_id": "e",
                            "answer_text": "Les documents présentant ces \"conditions et limites de validité\" accompagnent systématiquement les modèles tout au long de leur cycle de vie",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        }
                    }
                },
                "element 3": {
                    "order_id": "3",
                    "name": "Analyse et partage d'incidents",
                    "condition": "n/a",
                    "question_text": "Dans le cadre des projets de data science, lorsqu'un comportement inattendu d'un modèle est observé :",
                    "question_type": "checkbox",
                    "answer_hint": "Sélectionner tous les éléments de réponse correspondant à des pratiques de votre organisation. Attention, certaines combinaisons ne seraient pas cohérentes",
                    "explanation_text": "La compréhension voire la maîtrise du comportement d'un modèle prédictif appris sont des défis complexes. De nombreuses recherches sont en cours pour développer des méthodes et des outils dans ce domaine, mais beaucoup reste à faire. Le partage par les praticiens des incidents et comportements inattendus qu'ils rencontrent contribue faire progresser la communauté.",
                    "resources": {
                        "0": {
                            "resource_type": "Software & Tools",
                            "resource_text": "[AI Incident Registry](http://aiid.partnershiponai.org/), Partnership on AI"
                        },
                        "1": {
                            "resource_type": "Web article",
                            "resource_text": "[Specification gaming examples in AI](https://docs.google.com/spreadsheets/d/e/2PACX-1vRPiprOaC3HsCf5Tuum8bRfzYUiKLRqJmbOoC-32JorNdfyTiRRsR6Ea5eWtvsWzuxo8bjOxCG84dAg/pubhtml), Victoria Krakovna"
                        },
                        "2": {
                            "resource_type": "Web article",
                            "resource_text": "[Learning from Tay's introduction](https://blogs.microsoft.com/blog/2016/03/25/learning-tays-introduction/) : analyse d'incident relative au chatbot Tay, Microsoft, 2016"
                        },
                        "3": {
                            "resource_type": "Academic paper",
                            "resource_text": "[Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable Claims](https://arxiv.org/pdf/2004.07213.pdf), §2.4 p.19, Avril 2020"
                        }
                    },
                    "answer_items": {
                        "4.3.a": {
                            "order_id": "a",
                            "answer_text": "À ce stade nous ne faisons pas d'analyse des incidents ou comportements inattendus observés",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "4.3.b": {
                            "order_id": "b",
                            "answer_text": "Nous analysons les incidents ou comportements inattendus rencontrés et les publions lorsque cela est pertinent (e.g. article, blog)",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "4.3.c": {
                            "order_id": "c",
                            "answer_text": "Nous nous impliquons dans des clubs, cercles, ou associations professionnelles dans le domaine de la data science, et y faisons des retours d'expérience des incidents comportements inattendus que nous observons",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        }
                    }
                },
                "element 4": {
                    "order_id": "4",
                    "name": "Chaîne de valeur et de responsabilités",
                    "condition": "n/a",
                    "question_text": "Dans le cas de figure des projets de data science où plusieurs acteurs, y compris internes à l'organisation (équipes, départements, filiales), sont parties prenantes tout au long de la chaîne de valeur et de responsabilités :",
                    "question_type": "checkbox",
                    "answer_hint": "Sélectionner tous les éléments de réponse correspondant à des pratiques de votre organisation. Attention, certaines combinaisons ne seraient pas cohérentes",
                    "explanation_text": "Il est important de s'assurer que les organisations en amont et en aval de la chaîne identifient et endossent bien leurs responsabilités sur leurs segments de la chaîne de valeur.",
                    "resources": {},
                    "answer_items": {
                        "4.4.a": {
                            "order_id": "a",
                            "answer_text": "Au sein de notre organisation les projets de data science sont menés de bout-en-bout par des équipes autonomes, y compris l'élaboration de jeux de données et l'exploitation pour son propre compte des modèles. En conséquence, pour chaque projet une équipe autonome est seule responsable",
                            "is_concerned_switch": 1,
                            "depends_on": ""
                        },
                        "4.4.b": {
                            "order_id": "b",
                            "answer_text": "Nous procédons systématiquement à l'identification des risques et responsabilités de chacune des parties prenantes internes ou externes avec lesquelles nous collaborons",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        },
                        "4.4.c": {
                            "order_id": "c",
                            "answer_text": "Nous contractualisons systématiquement avec les acteurs amont (e.g. fournisseurs de données) et aval (e.g. clients, partenaires utilisateurs de modèles)",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        }
                    }
                },
                "element 5": {
                    "order_id": "5",
                    "name": "Sous-traitance de tout ou partie des activités data science",
                    "condition": "n/a",
                    "question_text": "Les activités data science sous-traitées à une ou des organisation(s) tierce(s) sont soumises aux mêmes exigences que celles que votre organisation s'applique à elle-même :",
                    "question_type": "radio",
                    "answer_hint": "Sélectionner une seule réponse, correspondant le mieux au niveau de maturité de l'organisation sur ce sujet",
                    "explanation_text": "Comme dans les cadres connues du management des SI (ISO 27001) ou du RGPD, il est important de ne pas diluer les responsabilités dans des chaînes de sous-traitance non maîtrisées. Cela doit s'appliquer par exemple aux consultants, freelances qui viennent renforcer une équipe interne sur un projet de data science. Il est par exemple possible de demander aux sous-traitants de réaliser cette même évaluation pour leur propre compte et de partager avec vous leurs résultats.",
                    "resources": {},
                    "answer_items": {
                        "4.5.a": {
                            "order_id": "a",
                            "answer_text": "Non concerné, nous ne sous-traitons pas ces activités",
                            "is_concerned_switch": 1,
                            "depends_on": ""
                        },
                        "4.5.b": {
                            "order_id": "b",
                            "answer_text": "Oui, nos réponses à cette évaluation tiennent compte des pratiques de nos sous-traitants",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        },
                        "4.5.c": {
                            "order_id": "c",
                            "answer_text": "Non, nos réponses à cette évaluation ne s'appliquent pas à nos sous-traitants et sur certains points il est possible qu'ils soient moins avancés que nous",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        }
                    }
                },
                "element 6": {
                    "order_id": "6",
                    "name": "Répartition de la création de valeur",
                    "condition": "n/a",
                    "question_text": "Dans les cas de figure des projets de data science où plusieurs partenaires concourent aux côtés de votre organisation à l'élaboration d'un modèle, et que celui-ci est ou sera l'objet d'une activité économique :",
                    "question_type": "checkbox",
                    "answer_hint": "Sélectionner tous les éléments de réponse correspondant à des pratiques de votre organisation. Attention, certaines combinaisons ne seraient pas cohérentes",
                    "explanation_text": "Lorsque plusieurs partenaires collaborent pour l'élaboration d'un modèle, il est important que la répartition de valeur consécutives à une activité économique dans laquelle le modèle joue un rôle soit explicitée et contractualisée. Dans certains cas de figure cette question peut être complexe, par exemple lorsqu'un modèle est entraîné de manière distribuée sur plusieurs jeux de données.",
                    "resources": {
                        "0": {
                            "resource_type": "Code repository",
                            "resource_text": "[Exploration of dataset contributivity to a model in collaborative ML projects](https://github.com/SubstraFoundation/distributed-learning-contributivity), un projet open source animé par [Substra Foundation](https://www.substra.ai/)"
                        }
                    },
                    "answer_items": {
                        "4.6.a": {
                            "order_id": "a",
                            "answer_text": "Notre organisation exerce ses activités de data science de manière autonome, y compris l'élaboration de jeux de données et l'exploitation pour son propre compte des modèles. Elle n'est donc pas concernée",
                            "is_concerned_switch": 1,
                            "depends_on": ""
                        },
                        "4.6.b": {
                            "order_id": "b",
                            "answer_text": "À ce stade nous n'avons pas structuré cet aspect des projets de data science multi-partenaires",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        },
                        "4.6.c": {
                            "order_id": "c",
                            "answer_text": "Dans ces cas de figure nous contractualisons le volet économique de la relation avec les parties prenantes impliquées en amont du projet",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        },
                        "4.6.d": {
                            "order_id": "d",
                            "answer_text": "Notre organisation s'est dotée d'une politique encadrant de manière responsable le partage de valeur avec les parties prenantes impliquées",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        }
                    }
                }
            }
        },
        "section 5": {
            "order_id": "5",
            "name": "Utiliser des modèles en confiance et de manière responsable",
            "description": "Utiliser des systèmes automatiques basés sur des modèles dont les règles ont été \"apprises\" (et non définies et formalisées) interroge le fonctionnement des organisations. Il est important de préserver la capacité de réaction et la résilience de l'organisation utilisatrice, notamment pour traiter les cas de figure où les modèles prédictifs auront été à l'origine d'un résultat non souhaitable pour l'organisation ou ses parties prenantes.",
            "elements": {
                "element 1": {
                    "order_id": "1",
                    "name": "Utilisation de modèles prédictifs pour son propre compte",
                    "condition": "n/a",
                    "question_text": "Si votre organisation utilise pour son propre compte des modèles prédictifs :",
                    "question_type": "checkbox",
                    "answer_hint": "Sélectionner tous les éléments de réponse correspondant à des pratiques de votre organisation. Attention, certaines combinaisons ne seraient pas cohérentes",
                    "explanation_text": "Utiliser des systèmes automatiques basés sur des modèles dont les règles ont été \"apprises\" (et non définies et formalisées) interroge le fonctionnement des organisations. Il est important d'évaluer les conséquences et les réactions en cas d'incident. Par ailleurs il est important qu'une personne responsable soit clairement identifiée de manière à ne laisser aucune partie prenante démunie face à une conséquence inattendue ou inappropriée. Enfin il est important de s'interroger sur les \"conditions et limites de validité\" des modèles que l'on utilise afin de s'assurer que l'usage que l'on prévoit est bien en adéquation.",
                    "resources": {},
                    "answer_items": {
                        "5.1.a": {
                            "order_id": "a",
                            "answer_text": "Notre organisation n'utilise pas de modèles prédictifs élaborés par apprentissage automatique pour son propre compte",
                            "is_concerned_switch": 1,
                            "depends_on": ""
                        },
                        "5.1.b": {
                            "order_id": "b",
                            "answer_text": "**Un registre des modèles prédictifs** identifie tous les modèles utilisés par l'organisation, nous le maintenons à jour",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        },
                        "5.1.c": {
                            "order_id": "c",
                            "answer_text": "Pour chaque modèle nous disposons d'un **responsable point de contact** défini, identifiable et contactable simplement",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        },
                        "5.1.d": {
                            "order_id": "d",
                            "answer_text": "Pour chaque modèle, nous réalisons systématiquement une **évaluation des risques** consécutifs à d'éventuels incidents, défaillances ou biais",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        },
                        "5.1.e": {
                            "order_id": "e",
                            "answer_text": "Des outils de monitoring sont mis en place afin d'assurer une surveillance continue des systèmes de ML et peuvent déclencher des alertes directement auprès de l'équipe responsable",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        },
                        "5.1.f": {
                            "order_id": "f",
                            "answer_text": "Pour chaque modèle, nous définissons et testons une procédure de suspension du modèle et un mode de fonctionnement dégradé sans le modèle, pour parer au cas de figure où le modèle serait sujet à une défaillance ou un comportement anormal",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        },
                        "5.1.g": {
                            "order_id": "g",
                            "answer_text": "Pour chaque modèle, nous étudions sa généalogie de bout-en-bout (toutes les étapes et tous les choix qui ont conduit à son élaboration et son évaluation), ainsi que ses conditions et limites d'utilisation, pour comprendre le modèle avant de l'utiliser",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        },
                        "5.1.h": {
                            "order_id": "h",
                            "answer_text": "Nous utilisons toujours les modèles pour des **usages en adéquation avec leurs conditions et limites d'utilisation**",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        }
                    }
                },
                "element 2": {
                    "order_id": "2",
                    "name": "Développement de modèles prédictifs pour le compte de tiers",
                    "condition": "n/a",
                    "question_text": "Si votre organisation fournit à ses clients ou à des tiers, ou opère pour le compte de tiers des applications basées sur des modèles prédictifs :",
                    "question_type": "checkbox",
                    "answer_hint": "Sélectionner tous les éléments de réponse correspondant à des pratiques de votre organisation. Attention, certaines combinaisons ne seraient pas cohérentes",
                    "explanation_text": "Utiliser des systèmes automatiques basés sur des modèles dont les règles ont été \"apprises\" (et non définies et formalisées) interroge le fonctionnement des organisations. Il est important d'évaluer les conséquences et les réactions en cas d'incident. Par ailleurs il est important qu'une personne responsable soit clairement identifiée de manière à ne laisser aucune partie prenante démunie face à une conséquence inattendue ou inappropriée. Enfin il est important de s'interroger sur les \"conditions et limites de validité\" des modèles que l'on utilise afin de s'assurer que l'usage que l'on prévoit est bien en adéquation.",
                    "resources": {},
                    "answer_items": {
                        "5.2.a": {
                            "order_id": "a",
                            "answer_text": "Notre organisation ne fournit pas à ses clients ou des tiers, et n'opère pas pour le compte de tiers d'application basée sur des modèles prédictifs élaborés par apprentissage automatique",
                            "is_concerned_switch": 1,
                            "depends_on": ""
                        },
                        "5.2.b": {
                            "order_id": "b",
                            "answer_text": "**Un registre des modèles prédictifs** identifie tous les modèles ou applications utilisés par ses clients et/ou par l'organisation pour le compte de tiers, nous le maintenons à jour",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        },
                        "5.2.c": {
                            "order_id": "c",
                            "answer_text": "Pour chaque modèle ou application pour un client ou un tiers nous disposons d'un **responsable point de contact** défini, identifiable et joignable simplement",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        },
                        "5.2.d": {
                            "order_id": "d",
                            "answer_text": "Pour chaque modèle ou application pour un client ou un tiers, nous réalisons systématiquement une **évaluation des risques** consécutifs à d'éventuels, incidents, défaillances, biais",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        },
                        "5.2.e": {
                            "order_id": "e",
                            "answer_text": "Des outils de monitoring sont mis en place afin d'assurer une surveillance continue des systèmes de ML et peuvent déclencher des alertes directement auprès de l'équipe responsable",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        },
                        "5.2.f": {
                            "order_id": "f",
                            "answer_text": "Pour chaque modèle ou application pour un client ou un tiers, nous définissons et testons une procédure de suspension du modèle et un mode de fonctionnement dégradé sans le modèle, pour parer au cas de figure où le modèle serait sujet à une défaillance ou un comportement anormal",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        },
                        "5.2.g": {
                            "order_id": "g",
                            "answer_text": "Pour chaque modèle ou application pour un client ou un tiers, nous étudions sa généalogie de bout-en-bout et ses conditions et limites d'utilisation pour comprendre le modèle avant de l'utiliser",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        },
                        "5.2.h": {
                            "order_id": "h",
                            "answer_text": "Nous fournissons à nos clients ou opérons pour leur compte des modèles ou applications pour des **usages en adéquation avec leurs conditions et limites d'utilisation**",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        }
                    }
                },
                "element 3": {
                    "order_id": "3",
                    "name": "Gestion des prédictions problématiques, processus de contournement, _human agency_",
                    "condition": "n/a",
                    "question_text": "Les systèmes automatiques, en particulier lorsqu'ils s'appuient sur des modèles prédictifs appris, sont utilisés en production généralement pour gagner en efficacité. Il se trouve que par nature, ils génèrent de temps en temps des résultats non souhaitables pour l'organisation et ses parties prenantes (e.g. prédiction erronée), puisqu'ils ne généraliseront jamais une performance de 100%.",
                    "question_type": "checkbox",
                    "answer_hint": "Sélectionner tous les éléments de réponse correspondant à des pratiques de votre organisation. Attention, certaines combinaisons ne seraient pas cohérentes",
                    "explanation_text": "Utiliser des systèmes automatiques basés sur des modèles dont les règles ont été \"apprises\" (et non définies et formalisées) interroge le fonctionnement des organisations. Il est important de préserver la capacité de réaction et la résilience de l'organisation.",
                    "resources": {
                        "0": {
                            "resource_type": "Technical guide",
                            "resource_text": "*[Monitoring Machine Learning Models in Production - A comprehensive guide](https://christophergs.com/machine%20learning/2020/03/14/how-to-monitor-machine-learning-models/)*, Christopher Samiullah, March 2020"
                        }
                    },
                    "answer_items": {
                        "5.3.a": {
                            "order_id": "a",
                            "answer_text": "Notre organisation n'utilise pas de modèles prédictifs élaboré par apprentissage automatique pour son propre compte ou celui de ses clients, et ne fournit pas à ses clients d'application basée sur des modèles prédictifs",
                            "is_concerned_switch": 1,
                            "depends_on": ""
                        },
                        "5.3.b": {
                            "order_id": "b",
                            "answer_text": "Nous intégrons dans les systèmes automatiques s'appuyant sur des modèles prédictifs appris les fonctionnalités permettant de gérer ces cas de résultats non souhaitables. Cela est fait *ex ante*, en sollicitant un opérateur humain dans un certain nombre de cas où l'intervalle de confiance pour la décision automatique n'est pas satisfaisant",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        },
                        "5.3.c": {
                            "order_id": "c",
                            "answer_text": "Nous intégrons dans les systèmes automatiques s'appuyant sur des modèles prédictifs appris les fonctionnalités permettant de gérer ces cas de résultats non souhaitables. Cela est fait selon une modalité de gestion d'incident, c'est-à-dire de correction *ex post* du résultat non souhaitable",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        },
                        "5.3.d": {
                            "order_id": "d",
                            "answer_text": "Nous mettons en place des mécanismes permettant à un opérateur humain, dans certaines conditions définies, d'aller contre une décision d'un modèle s'il identifie que le modèle commet une erreur",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        },
                        "5.3.e": {
                            "order_id": "e",
                            "answer_text": "Nous appliquons systématiquement le principe de *human agency*, les sorties des modèles prédictifs que nous mettons en oeuvre sont utilisées par des opérateurs humains, et ne servent pas de déterminants à des décisions automatiques",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        }
                    }
                },
                "element 4": {
                    "order_id": "4",
                    "name": "Transparence vis-à-vis des parties prenantes interagissant avec un modèle prédictif appris",
                    "condition": "n/a",
                    "question_text": "Votre organisation utilise pour son propre compte, fournit à ses clients ou opère pour le compte de ses clients des applications basées sur des modèles prédictifs, avec lesquels sont à même d'interagir des utilisateurs. Que met-elle en place pour en informer les utilisateurs ?",
                    "question_type": "checkbox",
                    "answer_hint": "Sélectionner tous les éléments de réponse correspondant à des pratiques de votre organisation. Attention, certaines combinaisons ne seraient pas cohérentes",
                    "explanation_text": "Utiliser des systèmes automatiques basés sur des modèles dont les règles ont été \"apprises\" (et non définies et formalisées) interroge le fonctionnement des organisations mais également le rapport des utilisateurs aux systèmes et services numériques. Dans la plupart des cas il est important d'informer les utilisateurs qu'ils ne font pas face à des règles de gestion classiques.",
                    "resources": {
                        "0": {
                            "resource_type": "Academic paper",
                            "resource_text": "*[Counterfactual Explanations without Opening the Black Box: Automated Decisions and the GDPR](https://arxiv.org/abs/1711.00399)*, S. Wachter, B. Mittelstadt, C. Russell, 2018"
                        },
                        "1": {
                            "resource_type": "Technical guide",
                            "resource_text": "*[Interpretable Machine Learning - Counterfactual explanations](https://christophm.github.io/interpretable-ml-book/counterfactual.html)*, C. Molnar, 2020"
                        }
                    },
                    "answer_items": {
                        "5.4.a": {
                            "order_id": "a",
                            "answer_text": "Notre organisation n'utilise pas de modèles prédictifs élaborés par apprentissage automatique pour son propre compte ou celui de ses clients, et ne fournit pas à ses clients d'application basée sur des modèles prédictifs",
                            "is_concerned_switch": 1,
                            "depends_on": ""
                        },
                        "5.4.b": {
                            "order_id": "b",
                            "answer_text": "Les utilisateurs ne sont pas informés qu'ils interagissent avec un modèle prédictif appris",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        },
                        "5.4.c": {
                            "order_id": "c",
                            "answer_text": "Une notice d'information est mise à disposition dans les conditions générales d'utilisation du système ou un document équivalent, en libre accès",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        },
                        "5.4.d": {
                            "order_id": "d",
                            "answer_text": "Le système ou le service est explicite vis-à-vis de l'utilisateur quant au fait qu'un modèle prédictif appris est utilisé",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        },
                        "5.4.e": {
                            "order_id": "e",
                            "answer_text": "Le système ou le service propose à l'utilisateur des informations supplémentaires sur les résultats qu'aurait fourni le système ou le service dans des cas de figure légèrement différents",
                            "is_concerned_switch": 0,
                            "depends_on": "a"
                        }
                    }
                }
            }
        },
        "section 6": {
            "order_id": "6",
            "name": "Anticiper, suivre et minimiser les externalités de l'activité data science",
            "description": "La mise en place d'un système automatique basé sur un modèle prédictif peut générer des externalités négatives sociales et environnementales. En prendre conscience est indispensable, ainsi qu'anticiper, chercher à suivre et minimiser les différents impacts négatifs.",
            "elements": {
                "element 1": {
                    "order_id": "1",
                    "name": "Impact CO2",
                    "condition": "n/a",
                    "question_text": "Au sujet de l'impact CO2 de son activité data science, au sein de votre organisation :",
                    "question_type": "radio",
                    "answer_hint": "Sélectionner une seule réponse, correspondant le mieux au niveau de maturité de l'organisation sur ce sujet",
                    "explanation_text": "Il est important de s'interroger et de conscientiser les coûts environnementaux.",
                    "resources": {
                        "0": {
                            "resource_type": "Software & Tools",
                            "resource_text": "*[ML Impact Calculator](https://mlco2.github.io/impact/)*"
                        }
                    },
                    "answer_items": {
                        "6.1.a": {
                            "order_id": "a",
                            "answer_text": "À ce stade nous ne nous sommes pas penchés sur l'impact CO2 de notre activité data science ou de nos modèles prédictifs",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "6.1.b": {
                            "order_id": "b",
                            "answer_text": "Nous avons défini des indicateurs pour savoir quoi mesurer précisément",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "6.1.c": {
                            "order_id": "c",
                            "answer_text": "Nous avons défini des indicateurs et nous incluons leurs mesures dans les généalogies de bout-en-bout des modèles",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "6.1.d": {
                            "order_id": "d",
                            "answer_text": "Nous avons défini des indicateurs et nous les suivons régulièrement",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "6.1.e": {
                            "order_id": "e",
                            "answer_text": "Nous avons défini des indicateurs, nous les suivons régulièrement, et nous nous sommes fixés des objectifs d'amélioration",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        }
                    }
                },
                "element 2": {
                    "order_id": "2",
                    "name": "Impact social",
                    "condition": "n/a",
                    "question_text": "Dans certains cas, la mise en place d'un système automatique basé sur un modèle prédictif peut générer des externalités négatives sur les parties prenantes amont (par exemple annotation de données), et sur les parties prenantes aval (par exemple automatisation de certains postes). Lors de chaque projet d'élaboration ou d'utilisation d'un modèle prédictif, votre organisation :",
                    "question_type": "radio",
                    "answer_hint": "Sélectionner une seule réponse, correspondant le mieux au niveau de maturité de l'organisation sur ce sujet",
                    "explanation_text": "Il est important de s'interroger et d'échanger avec ses parties prenantes. Cela vaut tant pour l'aval (e.g. automatisation de certains emplois) que pour l'amont (e.g. tâches d'annotations de données parfois d'une très grande violence).",
                    "resources": {},
                    "answer_items": {
                        "6.2.a": {
                            "order_id": "a",
                            "answer_text": "À ce stade nous ne nous penchons pas sur l'impact social de notre activité data science ou de nos modèles prédictifs",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "6.2.b": {
                            "order_id": "b",
                            "answer_text": "Dans certains cas nous nous interrogeons sur l'impact social",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "6.2.c": {
                            "order_id": "c",
                            "answer_text": "Nous menons ce travail de réflexion sur l'impact social à chaque projet",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "6.2.d": {
                            "order_id": "d",
                            "answer_text": "Nous menons ce travail de réflexion sur l'impact social à chaque projet et l'impact social est documenté dans la généalogie de bout-en-bout de chaque modèle",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "6.2.e": {
                            "order_id": "e",
                            "answer_text": "Nous menons ce travail de réflexion sur l'impact social à chaque projet, l'impact social est documenté dans la généalogie de bout-en-bout de chaque modèle, et nous entamons systématiquement un dialogue avec les parties prenantes concernées amont et aval",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        }
                    }
                },
                "element 3": {
                    "order_id": "3",
                    "name": "Ethique et non-malfaisance",
                    "condition": "n/a",
                    "question_text": "Au sein de votre organisation :",
                    "question_type": "checkbox",
                    "answer_hint": "Sélectionner tous les éléments de réponse correspondant à des pratiques de votre organisation. Attention, certaines combinaisons ne seraient pas cohérentes",
                    "explanation_text": "Travailler sur de grands volumes de données dont certaines peuvent être sensibles, utiliser des systèmes automatiques basés sur des modèles dont les règles ont été \"apprises\" (et non définies et formalisées) interrogent le fonctionnement des organisations et la responsabilité individuelle de chacun, impose d'avoir une réflexion sur l'usage qui en est fait. Il est donc important que l'organisation s'assure que les enjeux éthiques ne soient pas inconnus de son personnel.\nUn exemple qui revient : certains systèmes ou services d'IA conçus pour s'adapter au comportement des utilisateurs peuvent influencer ceux-ci (par exemple en cherchant à maximiser leurs temps d'utilisation ou les sommes qu'ils dépensent) et présenter des risques non négligeables de manipulation ou d'addiction.",
                    "resources": {
                        "0": {
                            "resource_type": "Official report",
                            "resource_text": "Rapport *[Éthique et responsabilité des algorithmes publics](https://www.etalab.gouv.fr/wp-content/uploads/2020/01/Rapport-ENA-Ethique-et-responsabilit%C3%A9-des-algorithmes-publics.pdf)*, Etalab / ENA, Janvier 2020"
                        },
                        "1": {
                            "resource_type": "Public declaration",
                            "resource_text": "*[Déclaration de Montréal pour l'IA responsable](https://www.declarationmontreal-iaresponsable.com/la-declaration)*"
                        },
                        "2": {
                            "resource_type": "Public declaration",
                            "resource_text": "*[Serment Holberton-Turing](https://www.holbertonturingoath.org/accueil)*"
                        },
                        "3": {
                            "resource_type": "Public declaration",
                            "resource_text": "*[Serment d'Hippocrate pour data scientist](https://hippocrate.tech/)*"
                        },
                        "4": {
                            "resource_type": "Public declaration",
                            "resource_text": "*[Future of Life's AI principles](https://futureoflife.org/ai-principles/)*"
                        },
                        "5": {
                            "resource_type": "Public declaration",
                            "resource_text": "*[Charte internationale pour une IA inclusive](https://charteia.arborus.org/)*, Arborus et Orange"
                        },
                        "6": {
                            "resource_type": "Course",
                            "resource_text": "*[Practical data ethics](https://ethics.fast.ai/)*, fast.ai : un excellent cours en ligne combinant listes de lectures et vidéos didactiques"
                        }
                    },
                    "answer_items": {
                        "6.3.a": {
                            "order_id": "a",
                            "answer_text": "À ce stade nous ne nous sommes pas encore penchés sur la dimension éthique",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "6.3.b": {
                            "order_id": "b",
                            "answer_text": "Les collaborateurs concernés par les activités data science reçoivent une formation à l'éthique",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "6.3.c": {
                            "order_id": "c",
                            "answer_text": "Notre organisation s'est dotée d'une politique en matière d'éthique",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        },
                        "6.3.d": {
                            "order_id": "d",
                            "answer_text": "Sur les projets le justifiant, nous mettons en place un comité d'éthique indépendant ou nous sollicitons l'évaluation d'un organisme validant l'éthique des projets",
                            "is_concerned_switch": 0,
                            "depends_on": ""
                        }
                    }
                }
            }
        }
    }
}