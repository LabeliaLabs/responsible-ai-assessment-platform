{
    "version": "0.63",
    "name": "DSRC Assessment - English",
    "language": "en",
    "timestamp": "18-Feb-2021 (10:54:15.032061)",
    "sections": {
        "section 1": {
            "order_id": "1",
            "name": "Protecting personal or confidential data",
            "keyword": "Data privacy",
            "description": "The use of personal or confidential data carries the risk of exposure of such data, which can have very detrimental consequences for the producers, controllers or subjects of such data. Particularly in data science projects, they must therefore be protected and the risks of their leakage or exposure must be minimised.",
            "elements": {
                "element 1": {
                    "order_id": "1",
                    "name": "Applicable legislation and contractual requirements - Identification",
                    "condition": "n/a",
                    "question_text": "n/a",
                    "question_type": "checkbox",
                    "answer_hint": "Select one answer only, which best corresponds to the level of maturity of the organisation on this topic",
                    "explanation_text": "It is crucial to put in place processes to know and follow the evolution of applicable regulations (very specific in certain fields, for example in the banking sector), as well as to document the approaches and choices made to comply with each data science project. Interesting example(s) : [Welfare surveillance system violates human rights, Dutch court rules](https://www.theguardian.com/technology/2020/feb/05/welfare-surveillance-system-violates-human-rights-dutch-court-rules).",
                    "resources": {
                        "0": {
                            "resource_type": "Official report",
                            "resource_text": "[Big data, artificial intelligence, machine learning and data protection](https://ico.org.uk/media/for-organisations/documents/2013559/big-data-ai-ml-and-data-protection.pdf), EU Information Commissioner's Office, 2017"
                        },
                        "1": {
                            "resource_type": "Web article",
                            "resource_text": "[Artificial Intelligence and the GDPR: how do they interact](https://www.avocats-mathias.com/technologies-avancees/artificial-intelligence-gdpr), Mathias Avocats, November 2017"
                        },
                        "2": {
                            "resource_type": "Web article",
                            "resource_text": "[How to develop Artificial Intelligence that is GDPR-friendly](https://techgdpr.com/blog/develop-artificial-intelligence-ai-gdpr-friendly/), Tech GDRP blog, February 2019"
                        },
                        "3": {
                            "resource_type": "Video",
                            "resource_text": "[What is the impact of GDPR on AI and Machine Learning](https://www.youtube.com/watch?v=RLEtyfmsfs4&app=desktop), SwissAI Machine Learning Meetup, September 2018"
                        },
                        "4": {
                            "resource_type": "Technical guide",
                            "resource_text": "[L'Atelier RGPD](https://atelier-rgpd.cnil.fr/), online training offered by the CNIL (French data protection authority), in French"
                        }
                    },
                    "answer_items": {
                        "1.1.a": {
                            "order_id": "a",
                            "answer_text": "Not yet identified",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        },
                        "1.1.b": {
                            "order_id": "b",
                            "answer_text": "Partially identified or in the process of identification",
                            "is_concerned_switch": 0,
                            "score_value": 0.25
                        },
                        "1.1.c": {
                            "order_id": "c",
                            "answer_text": "Identified",
                            "is_concerned_switch": 0,
                            "score_value": 0.5
                        },
                        "1.1.d": {
                            "order_id": "d",
                            "answer_text": "Identified and known by our collaborators",
                            "is_concerned_switch": 0,
                            "score_value": 0.75
                        },
                        "1.1.e": {
                            "order_id": "e",
                            "answer_text": "Identified, documented and known by our collaborators",
                            "is_concerned_switch": 0,
                            "score_value": 1.0
                        }
                    },
                    "element_max_score": 2.5
                },
                "element 2": {
                    "order_id": "2",
                    "name": "Applicable legislation and contractual requirements - Compliance approach",
                    "condition": "n/a",
                    "question_text": "n/a",
                    "question_type": "checkbox",
                    "answer_hint": "Select one answer only, which best corresponds to the level of maturity of the organisation on this topic",
                    "explanation_text": "It is a question of questioning the management of personal or confidential data (storage, access, transfer, protection, responsibilities...), and documenting the choices made.",
                    "resources": {},
                    "answer_items": {
                        "1.2.a": {
                            "order_id": "a",
                            "answer_text": "Informal, based on individual responsibility and competence",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        },
                        "1.2.b": {
                            "order_id": "b",
                            "answer_text": "Formalized and accessible to all collaborators",
                            "is_concerned_switch": 0,
                            "score_value": 0.33
                        },
                        "1.2.c": {
                            "order_id": "c",
                            "answer_text": "Formalized and known by collaborators",
                            "is_concerned_switch": 0,
                            "score_value": 0.67
                        },
                        "1.2.d": {
                            "order_id": "d",
                            "answer_text": "Formalized, known by employees, documented for each processing of personal or confidential data",
                            "is_concerned_switch": 0,
                            "score_value": 1.0
                        }
                    },
                    "element_max_score": 2.0
                },
                "element 3": {
                    "order_id": "3",
                    "name": "Applicable legislation and contractual requirements - Regulatory surveillance",
                    "condition": "n/a",
                    "question_text": "n/a",
                    "question_type": "checkbox",
                    "answer_hint": "Select one answer only, which best corresponds to the level of maturity of the organisation on this topic",
                    "explanation_text": "In addition to identifying regulations and compliance approaches, it is important to set up a surveillance processe to know and follow **the evolution** of applicable regulations (which can be very specific in certain sectors). Interesting example(s) : [Welfare surveillance system violates human rights, Dutch court rules](https://www.theguardian.com/technology/2020/feb/05/welfare-surveillance-system-violates-human-rights-dutch-court-rules).",
                    "resources": {},
                    "answer_items": {
                        "1.3.a": {
                            "order_id": "a",
                            "answer_text": "We do not really monitor the regulatory environment",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        },
                        "1.3.b": {
                            "order_id": "b",
                            "answer_text": "We keep an informal watch, each employee sends back information via internal communication channels",
                            "is_concerned_switch": 0,
                            "score_value": 0.25
                        },
                        "1.3.c": {
                            "order_id": "c",
                            "answer_text": "We have a formal surveillance, with identified collaborators in charge and a documented process",
                            "is_concerned_switch": 0,
                            "score_value": 0.5
                        }
                    },
                    "element_max_score": 0.75
                },
                "element 4": {
                    "order_id": "4",
                    "name": "Applicable legislation and contractual requirements - Auditing and certification",
                    "condition": "n/a",
                    "question_text": "n/a",
                    "question_type": "checkbox",
                    "answer_hint": "Select one answer only, which best corresponds to the level of maturity of the organisation on this topic",
                    "explanation_text": "In many sectors there are specific compliance requirements. It is generally possible to formalise an organisation's compliance through certification or a specialised audit, or by obtaining a label.",
                    "resources": {},
                    "answer_items": {
                        "1.4.a": {
                            "order_id": "a",
                            "answer_text": "Yes",
                            "is_concerned_switch": 0,
                            "score_value": 1.5
                        },
                        "1.4.b": {
                            "order_id": "b",
                            "answer_text": "No",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        }
                    },
                    "element_max_score": 1.5
                },
                "element 5": {
                    "order_id": "5",
                    "name": "Data minimisation principle",
                    "condition": "n/a",
                    "question_text": "n/a",
                    "question_type": "checkbox",
                    "answer_hint": "Select one answer only, which best corresponds to the level of maturity of the organisation on this topic",
                    "explanation_text": "The data minimisation principle is sometimes also referred to as \"privacy by design\". It is one of the pillars of the RGPD in the European Union.",
                    "resources": {},
                    "answer_items": {
                        "1.5.a": {
                            "order_id": "a",
                            "answer_text": "We take care not to use any personal or confidential data. We are not concerned by this risk area",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        },
                        "1.5.b": {
                            "order_id": "b",
                            "answer_text": "We need to use personal or confidential data in certain projects and the data minimisation principle is then systematically applied",
                            "is_concerned_switch": 0,
                            "score_value": 2.0
                        },
                        "1.5.c": {
                            "order_id": "c",
                            "answer_text": "Employees are aware of the data minimisation principle and generally apply it",
                            "is_concerned_switch": 0,
                            "score_value": 1.0
                        },
                        "1.5.d": {
                            "order_id": "d",
                            "answer_text": "The \"who can do the most can do the least\" reflex with regard to data still exists here and there within our organisation. In some projects, we keep datasets that are much richer in personal and confidential data than what is strictly useful to the project",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        }
                    },
                    "element_max_score": 3.0
                },
                "element 6": {
                    "order_id": "6",
                    "name": "Project involving new processing of personal or confidential data",
                    "condition": "n/a",
                    "question_text": "n/a",
                    "question_type": "checkbox",
                    "answer_hint": "Select all the answer items that correspond to practices in your organisation",
                    "explanation_text": "The *Privacy Impact Assessment* (PIA) is a method for assessing the impact of a data processing, similar to traditional risk assessment methods. In certain cases, for example where a processing operation presents high risks to the rights and freedoms of natural persons, the GDPR makes it obligatory to carry out an PIA before the processing operation is carried out.",
                    "resources": {},
                    "answer_items": {
                        "1.6.a": {
                            "order_id": "a",
                            "answer_text": "We elaborate a Privacy Impact Assessment (PIA)",
                            "is_concerned_switch": 0,
                            "score_value": 0.34
                        },
                        "1.6.b": {
                            "order_id": "b",
                            "answer_text": "We implement data protection measures (in particular concerning the transfer, storage and access to the data concerned)",
                            "is_concerned_switch": 0,
                            "score_value": 0.33
                        },
                        "1.6.c": {
                            "order_id": "c",
                            "answer_text": "We contractualise relations with suppliers and customers and the responsibilities that arise from them",
                            "is_concerned_switch": 0,
                            "score_value": 0.33
                        },
                        "1.6.d": {
                            "order_id": "d",
                            "answer_text": "We have not yet set up an organised approach to these subjects",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        }
                    },
                    "element_max_score": 1.0
                },
                "element 7": {
                    "order_id": "7",
                    "name": "Machine Learning security - Knowledge level",
                    "condition": "n/a",
                    "question_text": "n/a",
                    "question_type": "checkbox",
                    "answer_hint": "Select one answer only, which best corresponds to the level of maturity of the organisation on this topic",
                    "explanation_text": "The state of the art in ML security is constantly evolving. While it is impossible to guard against all vulnerabilities at all times, it is crucial to be aware of them and to keep a watch on them. The article [Demystifying the Membership Inference Attack](https://medium.com/disaitek/demystifying-the-membership-inference-attack-e33e510a0c39) is for example an interesting entry point in the context of sensitive data.",
                    "resources": {
                        "0": {
                            "resource_type": "Technical guide",
                            "resource_text": "*[Privacy Enhancing Technologies Decision Tree (v2)](https://www.private-ai.ca/PETs_Decision_Tree.png)*, Private AI, 2020"
                        },
                        "1": {
                            "resource_type": "Web article",
                            "resource_text": "*[The secret-sharer: evaluating and testing unintended memorization in neural networks](https://blog.acolyer.org/2019/09/23/the-secret-sharer/)*, A. Colyer, 2019"
                        },
                        "2": {
                            "resource_type": "Academic paper",
                            "resource_text": "*[Membership Inference Attacks against Machine Learning Models](https://arxiv.org/abs/1610.05820)*, R. Shokri, M. Stronati, C. Song, V. Shmatikov, 2017"
                        },
                        "3": {
                            "resource_type": "Software & Tools",
                            "resource_text": "*[ML Privacy Meter](https://github.com/privacytrustlab/ml_privacy_meter): a tool to quantify the privacy risks of machine learning models with respect to inference attacks*."
                        },
                        "4": {
                            "resource_type": "Web article",
                            "resource_text": "*[Demystifying the membership inference attack](https://medium.com/disaitek/demystifying-the-membership-inference-attack-e33e510a0c39)*, Disaitek, 2019"
                        },
                        "5": {
                            "resource_type": "Academic paper",
                            "resource_text": "*[Inverting Gradients - How easy is it to break privacy in federated learning](https://arxiv.org/abs/2003.14053)*, J. Geiping, H. Bauermeister, H. Dröge, M. Moeller, 2020"
                        },
                        "6": {
                            "resource_type": "Web article",
                            "resource_text": "*[Top Five ML risks](https://github.com/OWASP/Top-5-Machine-Learning-Risks/blob/master/Top%205%20Machine%20Learning%20Risks.md)*, OWASP"
                        },
                        "7": {
                            "resource_type": "Software & Tools",
                            "resource_text": "Tools for *differential privacy*: Google *[differential privacy library](https://github.com/google/differential-privacy)*, and the Python [PyDP](https://github.com/OpenMined/PyDP) wrapper from OpenMined"
                        },
                        "8": {
                            "resource_type": "Web article",
                            "resource_text": "The *distillation* of a model, in addition to the compression it provides, can be used as a measure to protect the model and the training data used, see for example *[Knowledge Distillation: Simplified](https://towardsdatascience.com/knowledge-distillation-simplified-dd4973dbc764)*, Towards Data Science, 2019."
                        },
                        "9": {
                            "resource_type": "Academic paper",
                            "resource_text": "*[Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531)*, G. Hinton, O. Vinyals, J. Dean, 2015"
                        }
                    },
                    "answer_items": {
                        "1.7.a": {
                            "order_id": "a",
                            "answer_text": "Complete beginner",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        },
                        "1.7.b": {
                            "order_id": "b",
                            "answer_text": "Basic",
                            "is_concerned_switch": 0,
                            "score_value": 0.33
                        },
                        "1.7.c": {
                            "order_id": "c",
                            "answer_text": "Confirmed",
                            "is_concerned_switch": 0,
                            "score_value": 1.0
                        },
                        "1.7.d": {
                            "order_id": "d",
                            "answer_text": "Expert",
                            "is_concerned_switch": 0,
                            "score_value": 1.5
                        }
                    },
                    "element_max_score": 2.83
                },
                "element 8": {
                    "order_id": "8",
                    "name": "Machine Learning security - Implementation",
                    "condition": "n/a",
                    "question_text": "n/a",
                    "question_type": "checkbox",
                    "answer_hint": "Select all the answer items that correspond to practices in your organisation",
                    "explanation_text": "The state of the art in ML security is constantly evolving. While it is impossible to guard against all vulnerabilities at all times, it is crucial to be aware of them and to keep a watch on them. The article [Demystifying the Membership Inference Attack](https://medium.com/disaitek/demystifying-the-membership-inference-attack-e33e510a0c39) is for example an interesting entry point in the context of sensitive data.\n\nDepending on the level of risk and sensitivity of the projects, certain technical approaches to guard against them will be selected and implemented. It is important to follow the evolution of research and state-of-the-art practices, and to document the choices made. The notion of \"end-to-end genealogy\" is introduced here.",
                    "resources": {
                        "0": {
                            "resource_type": "Technical guide",
                            "resource_text": "*[Privacy Enhancing Technologies Decision Tree (v2)](https://www.private-ai.ca/PETs_Decision_Tree.png)*, Private AI, 2020"
                        },
                        "1": {
                            "resource_type": "Web article",
                            "resource_text": "*[The secret-sharer: evaluating and testing unintended memorization in neural networks](https://blog.acolyer.org/2019/09/23/the-secret-sharer/)*, A. Colyer, 2019"
                        },
                        "2": {
                            "resource_type": "Academic paper",
                            "resource_text": "*[Membership Inference Attacks against Machine Learning Models](https://arxiv.org/abs/1610.05820)*, R. Shokri, M. Stronati, C. Song, V. Shmatikov, 2017"
                        },
                        "3": {
                            "resource_type": "Software & Tools",
                            "resource_text": "*[ML Privacy Meter](https://github.com/privacytrustlab/ml_privacy_meter): a tool to quantify the privacy risks of machine learning models with respect to inference attacks*."
                        },
                        "4": {
                            "resource_type": "Web article",
                            "resource_text": "*[Demystifying the membership inference attack](https://medium.com/disaitek/demystifying-the-membership-inference-attack-e33e510a0c39)*, Disaitek, 2019"
                        },
                        "5": {
                            "resource_type": "Academic paper",
                            "resource_text": "*[Inverting Gradients - How easy is it to break privacy in federated learning](https://arxiv.org/abs/2003.14053)*, J. Geiping, H. Bauermeister, H. Dröge, M. Moeller, 2020"
                        },
                        "6": {
                            "resource_type": "Web article",
                            "resource_text": "*[Top Five ML risks](https://github.com/OWASP/Top-5-Machine-Learning-Risks/blob/master/Top%205%20Machine%20Learning%20Risks.md)*, OWASP"
                        },
                        "7": {
                            "resource_type": "Software & Tools",
                            "resource_text": "Tools for *differential privacy*: Google *[differential privacy library](https://github.com/google/differential-privacy)*, and the Python [PyDP](https://github.com/OpenMined/PyDP) wrapper from OpenMined"
                        },
                        "8": {
                            "resource_type": "Web article",
                            "resource_text": "The *distillation* of a model, in addition to the compression it provides, can be used as a measure to protect the model and the training data used, see for example *[Knowledge Distillation: Simplified](https://towardsdatascience.com/knowledge-distillation-simplified-dd4973dbc764)*, Towards Data Science, 2019."
                        },
                        "9": {
                            "resource_type": "Academic paper",
                            "resource_text": "*[Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531)*, G. Hinton, O. Vinyals, J. Dean, 2015"
                        }
                    },
                    "answer_items": {
                        "1.8.a": {
                            "order_id": "a",
                            "answer_text": "We keep a technical watch on the main attacks and measures to mitigate them",
                            "is_concerned_switch": 0,
                            "score_value": 0.5
                        },
                        "1.8.b": {
                            "order_id": "b",
                            "answer_text": "Employees receive regular information and training to help them develop their skills in this area",
                            "is_concerned_switch": 0,
                            "score_value": 0.5
                        },
                        "1.8.c": {
                            "order_id": "c",
                            "answer_text": "In some projects, we implement specific techniques to reduce the risks associated with the models we develop (for example: differential privacy, distillation, etc.)",
                            "is_concerned_switch": 0,
                            "score_value": 1.0
                        },
                        "1.8.d": {
                            "order_id": "d",
                            "answer_text": "On each project, the vulnerabilities that apply to it and the techniques implemented are documented (e.g. in the end-to-end genealogy of each model, see Section 4 and Element 4.1 for more information on this concept)",
                            "is_concerned_switch": 0,
                            "score_value": 0.5
                        },
                        "1.8.e": {
                            "order_id": "e",
                            "answer_text": "We have not yet set up an organised approach to these subjects",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        }
                    },
                    "element_max_score": 2.5
                },
                "element 9": {
                    "order_id": "9",
                    "name": "Notification of safety incidents to the regulatory authorities",
                    "condition": "n/a",
                    "question_text": "n/a",
                    "question_type": "checkbox",
                    "answer_hint": "Select all the answer items that correspond to practices in your organisation",
                    "explanation_text": "In some sectors there are obligations to report safety incidents to the regulatory authorities (e.g. in France: CNIL, ANSSI, ARS, etc.). An interesting entry point: [Notifications of safety incidents to regulatory authorities: how to organise and who to contact](https://www.cnil.fr/fr/notifications-dincidents-de-securite-aux-autorites-de-regulation-comment-sorganiser-et-qui-sadresser) on the CNIL website.",
                    "resources": {},
                    "answer_items": {
                        "1.9.a": {
                            "order_id": "a",
                            "answer_text": "We have a process describing the course of action in such cases",
                            "is_concerned_switch": 0,
                            "score_value": 0.34
                        },
                        "1.9.b": {
                            "order_id": "b",
                            "answer_text": "Our process includes communication to the stakeholders in question",
                            "is_concerned_switch": 0,
                            "score_value": 0.33
                        },
                        "1.9.c": {
                            "order_id": "c",
                            "answer_text": "Our process references the authorities to whom we must report",
                            "is_concerned_switch": 0,
                            "score_value": 0.33
                        },
                        "1.9.d": {
                            "order_id": "d",
                            "answer_text": "We have not yet put in place a procedure for such cases",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        }
                    },
                    "element_max_score": 1.0
                }
            },
            "section_max_score": 17.08
        },
        "section 2": {
            "order_id": "2",
            "name": "Preventing bias, developing non-discriminatory models",
            "keyword": "Biases and discrimination",
            "description": "The use of predictive models learned from historical data can be counterproductive when historical data are contaminated by problematic phenomena (e.g. quality of certain data points, non-comparable data, social phenomena undesirable due to the time period, etc.). A key challenge for responsible and trustworthy data science is to respect the principle of diversity, non-discrimination and equity (described for example in section 1.5 of the EU [Ethics Guidelines for Trustworthy AI](https://ec.europa.eu/newsroom/dae/document.cfm?doc_id=60419)). It is therefore essential to question this risk and to study the nature of the data used, the conditions under which they were produced and collected, and what they represent.\nAmong other things, in some cases a specification of the equity sought between populations must also be defined. The equity of a model can [be defined in several ways that may be inconsistent with each other](https://papers.nips.cc/paper/6995-counterfactual-fairness), and the interpretation of performance scores must therefore be made within the framework of one of these definitions.",
            "elements": {
                "element 1": {
                    "order_id": "1",
                    "name": "Analysis of the training data",
                    "condition": "n/a",
                    "question_text": "n/a",
                    "question_type": "checkbox",
                    "answer_hint": "Select one answer only, which best corresponds to the level of maturity of the organisation on this topic",
                    "explanation_text": "It is a question of ensuring that oneself considers these subjects and therefore questions the training data, the way in which it was produced, etc.",
                    "resources": {
                        "0": {
                            "resource_type": "Web article",
                            "resource_text": "*[Hidden Bias](https://pair.withgoogle.com/explorables/hidden-bias/)* explorable from [PAIR](https://pair.withgoogle.com/)"
                        },
                        "1": {
                            "resource_type": "Technical guide",
                            "resource_text": "*[Tour of Data Sampling Methods for Imbalanced Classification](https://machinelearningmastery.com/data-sampling-methods-for-imbalanced-classification/)*"
                        }
                    },
                    "answer_items": {
                        "2.1.a": {
                            "order_id": "a",
                            "answer_text": "Operates informally on this subject and relies on the practices of each collaborator involved",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        },
                        "2.1.b": {
                            "order_id": "b",
                            "answer_text": "Does not have a documented approach to the subject, but the collaborators involved are trained on the risks and best practices on the subject",
                            "is_concerned_switch": 0,
                            "score_value": 0.75
                        },
                        "2.1.c": {
                            "order_id": "c",
                            "answer_text": "Has a documented approach that is systematically implemented",
                            "is_concerned_switch": 0,
                            "score_value": 1.5
                        }
                    },
                    "element_max_score": 2.25
                },
                "element 2": {
                    "order_id": "2",
                    "name": "Risk of discrimination against certain social groups",
                    "condition": "n/a",
                    "question_text": "n/a",
                    "question_type": "checkbox",
                    "answer_hint": "Select one answer only, which best corresponds to the level of maturity of the organisation on this topic",
                    "explanation_text": "n/a",
                    "resources": {},
                    "answer_items": {
                        "2.2.a": {
                            "order_id": "a",
                            "answer_text": "Concerned",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        },
                        "2.2.b": {
                            "order_id": "b",
                            "answer_text": "Not concerned",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        }
                    },
                    "element_max_score": 0.0
                },
                "element 3": {
                    "order_id": "3",
                    "name": "Preventing discriminatory bias",
                    "condition": "n/a",
                    "question_text": "n/a",
                    "question_type": "checkbox",
                    "answer_hint": "Select all the answer items that correspond to practices in your organisation",
                    "explanation_text": "It is a question of systematically questioning, for each data science project and according to the objective and target use of the model that one wants to develop, the features that may directly or indirectly be the source of a risk of discriminatory bias. The term \"protected attribute\" or \"protected variable\" is used to refer to attributes whose values define sub-populations at risk of discrimination.\nComplement on the use of synthetic data and _data augmentation_, _re-weighting_ approaches in order to reduce possible biases in the data sets: when such techniques are used it is important to make them explicit, otherwise there is a risk of losing information on how a model was developed.",
                    "resources": {
                        "0": {
                            "resource_type": "Web article",
                            "resource_text": "*[Unfair biases in Machine Learning: what, why, where and how to obliterate them](https://www.mlsecurity.ai/post/unfair-biases-in-machine-learning-what-why-where-and-how-to-obliterate-them)*, blog ML Security, P. Irolla, April 2020"
                        },
                        "1": {
                            "resource_type": "Web article",
                            "resource_text": "[Awful AI](https://github.com/daviddao/awful-ai), a registry of worrying AI services or projects, David Dao"
                        },
                        "2": {
                            "resource_type": "Technical guide",
                            "resource_text": "*[A Tutorial on Fairness in Machine Learning](https://towardsdatascience.com/a-tutorial-on-fairness-in-machine-learning-3ff8ba1040cb)*, Towards Data Science blog, Z. Zhong, October 2018"
                        },
                        "3": {
                            "resource_type": "Web article",
                            "resource_text": "*[Measuring fairness](https://pair.withgoogle.com/explorables/measuring-fairness)* explorable, [PAIR](https://pair.withgoogle.com/)"
                        },
                        "4": {
                            "resource_type": "Software & Tools",
                            "resource_text": "*[AI Fairness 360](https://developer.ibm.com/technologies/artificial-intelligence/projects/ai-fairness-360/): an open source software toolkit that can help detect and remove bias in machine learning models*, IBM"
                        },
                        "5": {
                            "resource_type": "Academic paper",
                            "resource_text": "*Fairness metrics* : *[counterfactual fairness](https://papers.nips.cc/paper/6995-counterfactual-fairness)*"
                        },
                        "6": {
                            "resource_type": "Academic paper",
                            "resource_text": "*Fairness metrics* : *[adversarial debiaising](https://arxiv.org/pdf/1801.07593.pdf)*"
                        },
                        "7": {
                            "resource_type": "Technical guide",
                            "resource_text": "Book *Fair ML* : *[Fairness and machine learning - Limitations and opportunities](https://fairmlbook.org/)*, Solon Barocas, Moritz Hardt, Arvind Narayanan, December 2019"
                        }
                    },
                    "answer_items": {
                        "2.3.a": {
                            "order_id": "a",
                            "answer_text": "We pay particular attention to the identification of protected attributes and their possible proxies (e.g. studying one by one the variables used as model inputs to identify the correlations they might have with sensitive data)",
                            "is_concerned_switch": 0,
                            "score_value": 0.5
                        },
                        "2.3.b": {
                            "order_id": "b",
                            "answer_text": "We carry out evaluations on test data from different sub-populations in order to identify possible problematic biases",
                            "is_concerned_switch": 0,
                            "score_value": 1.0
                        },
                        "2.3.c": {
                            "order_id": "c",
                            "answer_text": "We select and implement one or more justice and equity measure(s) (_fairness metrics_)",
                            "is_concerned_switch": 0,
                            "score_value": 1.0
                        },
                        "2.3.d": {
                            "order_id": "d",
                            "answer_text": "We use _data augmentation_ or _re-weighting_ approaches to reduce possible biases in the data sets",
                            "is_concerned_switch": 0,
                            "score_value": 0.5
                        },
                        "2.3.e": {
                            "order_id": "e",
                            "answer_text": "The above practices that we implement are duly documented and integrated into the end-to-end genealogy of the models concerned",
                            "is_concerned_switch": 0,
                            "score_value": 0.5
                        },
                        "2.3.f": {
                            "order_id": "f",
                            "answer_text": "We have not yet put in place any such measures",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        }
                    },
                    "element_max_score": 3.5
                }
            },
            "section_max_score": 5.75
        },
        "section 3": {
            "order_id": "3",
            "name": "Assessing model performance rigorously",
            "keyword": "Performance evaluation",
            "description": "The performance of the models is crucial for their adoption in products, systems or processes. Performance evaluation must therefore be rigorous.",
            "elements": {
                "element 1": {
                    "order_id": "1",
                    "name": "Separation of test datasets",
                    "condition": "n/a",
                    "question_text": "n/a",
                    "question_type": "checkbox",
                    "answer_hint": "Select all response items that correspond to practices in your organisation. Please note that some combinations would not be coherent",
                    "explanation_text": "Ensuring that training and test datasets are kept separated is a principle known and mastered by most organisations. It can however be tricky in some particular configurations (e.g. continuous learning, distributed learning *privacy-preserving*...).",
                    "resources": {},
                    "answer_items": {
                        "3.1.a": {
                            "order_id": "a",
                            "answer_text": "Operates informally on this subject and relies on the competence and responsibility of the collaborators involved",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        },
                        "3.1.b": {
                            "order_id": "b",
                            "answer_text": "Has a documented and systematically implemented approach to isolating test datasets",
                            "is_concerned_switch": 0,
                            "score_value": 0.5
                        },
                        "3.1.c": {
                            "order_id": "c",
                            "answer_text": "Uses a tool for versioning and tracing the training and test datasets used, thus enabling the non-contamination of test data to be checked or audited at a later stage",
                            "is_concerned_switch": 0,
                            "score_value": 1.0
                        },
                        "3.1.d": {
                            "order_id": "d",
                            "answer_text": "Systematically plans two or more sets of test data to increase resilience",
                            "is_concerned_switch": 0,
                            "score_value": 0.5
                        }
                    },
                    "element_max_score": 2.0
                },
                "element 2": {
                    "order_id": "2",
                    "name": "Privacy-preserving distributed learning projects",
                    "condition": "n/a",
                    "question_text": "n/a",
                    "question_type": "checkbox",
                    "answer_hint": "Select one answer only, which best corresponds to the level of maturity of the organisation on this topic",
                    "explanation_text": "In this type of distributed learning project under conditions where the data is kept confidential, the question arises of how to compose a test dataset, making sure that it does not also appear in the training dataset (e.g. at another partner's premises).",
                    "resources": {
                        "0": {
                            "resource_type": "Academic paper",
                            "resource_text": "[Stratified cross-validation for unbiased and privacy-preserving federated learning](https://arxiv.org/abs/2001.08090), R. Bey, R. Goussault, M. Benchoufi, R. Porcher, January 2020"
                        }
                    },
                    "answer_items": {
                        "3.2.a": {
                            "order_id": "a",
                            "answer_text": "We do not participate in *privacy-preserving* distributed learning projects",
                            "is_concerned_switch": 1,
                            "score_value": 0.0
                        },
                        "3.2.b": {
                            "order_id": "b",
                            "answer_text": "We master and implement approaches to develop test datasets in such a way that there is no cross-contamination between training and test data from different partners",
                            "is_concerned_switch": 0,
                            "score_value": 1.5
                        },
                        "3.2.c": {
                            "order_id": "c",
                            "answer_text": "At this stage we do not master the methods for developing test datasets in such a way that there is no cross-contamination between training and test data from the different partners",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        }
                    },
                    "element_max_score": 1.5
                },
                "element 3": {
                    "order_id": "3",
                    "name": "Analysis of validation and test data",
                    "condition": "n/a",
                    "question_text": "n/a",
                    "question_type": "checkbox",
                    "answer_hint": "Select one answer only, which best corresponds to the level of maturity of the organisation on this topic",
                    "explanation_text": "The use of predictive models that have been validated and tested on historical data can be counterproductive when the historical data in question is contaminated by problematic phenomena. It seems essential to question this risk and to study the nature of the data used, the conditions under which they were produced and assembled, and what they represent.",
                    "resources": {},
                    "answer_items": {
                        "3.3.a": {
                            "order_id": "a",
                            "answer_text": "Operates informally on this subject and relies on the practice of each collaborator member involved",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        },
                        "3.3.b": {
                            "order_id": "b",
                            "answer_text": "Does not have a documented approach to the subject, but the collaborators involved are trained on the risks and best practices on the subject",
                            "is_concerned_switch": 0,
                            "score_value": 0.5
                        },
                        "3.3.c": {
                            "order_id": "c",
                            "answer_text": "Has a documented approach that is systematically implemented",
                            "is_concerned_switch": 0,
                            "score_value": 1.0
                        }
                    },
                    "element_max_score": 1.5
                },
                "element 4": {
                    "order_id": "4",
                    "name": "Performance validation",
                    "condition": "n/a",
                    "question_text": "n/a",
                    "question_type": "checkbox",
                    "answer_hint": "Select all the answer items that correspond to practices in your organisation",
                    "explanation_text": "On choosing metrics upstream, see for example the risk of *[p-hacking / data dredging](https://en.wikipedia.org/wiki/Data_dredging)*.\nOn robustness, an intuitive definition is that a model is robust when its performance is stable when the input data is disturbed. For more information see the technical resources indicated.",
                    "resources": {
                        "0": {
                            "resource_type": "Web article",
                            "resource_text": "*[The Comprehensive Guide to Model Validation Framework: What is a Robust Machine Learning Model?](https://medium.com/@ODSC/the-comprehensive-guide-to-model-validation-framework-what-is-a-robust-machine-learning-model-7bdbc41c1702)*, Open Data Science, March 2020"
                        },
                        "1": {
                            "resource_type": "Web article",
                            "resource_text": "*[Testing Robustness Against Unforeseen Adversaries](https://openai.com/blog/testing-robustness/)*, Open AI, August 2019"
                        },
                        "2": {
                            "resource_type": "Academic paper",
                            "resource_text": "*Robustness metrics* : *[noise sensitivity score](https://arxiv.org/abs/1806.01477)*."
                        },
                        "3": {
                            "resource_type": "Technical guide",
                            "resource_text": "*[Adversarial Robustness - Theory and Practice](https://adversarial-ml-tutorial.org/)*, Z. Kolter and A. Madry"
                        }
                    },
                    "answer_items": {
                        "3.4.a": {
                            "order_id": "a",
                            "answer_text": "When developing a model, we choose the performance metric(s) prior to actually training the model, from among the most standard metrics possible",
                            "is_concerned_switch": 0,
                            "score_value": 0.5
                        },
                        "3.4.b": {
                            "order_id": "b",
                            "answer_text": "The implementation of robustness metrics is considered and evaluated for each modelling project, and applied by default in cases where the input data may be subject to fine-grain alterations (e.g. images, sounds)",
                            "is_concerned_switch": 0,
                            "score_value": 1.0
                        },
                        "3.4.c": {
                            "order_id": "c",
                            "answer_text": "The above practices that we implement are documented and integrated into the end-to-end genealogy of the models concerned, including the performance metrics chosen",
                            "is_concerned_switch": 0,
                            "score_value": 0.5
                        },
                        "3.4.d": {
                            "order_id": "d",
                            "answer_text": "We have not yet introduced any such measures",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        }
                    },
                    "element_max_score": 2.0
                },
                "element 5": {
                    "order_id": "5",
                    "name": "Monitoring model performance over time",
                    "condition": "n/a",
                    "question_text": "n/a",
                    "question_type": "checkbox",
                    "answer_hint": "Select all response items that correspond to practices in your organisation. Please note that some combinations would not be coherent",
                    "explanation_text": "Even on a stable model, there is a risk that the input data will no longer remain in the target distribution after a certain time (population & distribution), for example, a variable that would no longer be filled in at the same frequency as before by users in an IS. It is therefore necessary to regularly re-evaluate the performance of a model used in its context of use.\nMonitoring the performance of models over time is also particularly important in cases of continuous learning, where there is a risk of model degeneration.",
                    "resources": {
                        "0": {
                            "resource_type": "Technical guide",
                            "resource_text": "*[Continuous delivery for machine learning](https://martinfowler.com/articles/cd4ml.html)*, D. Sato, A. Wider, C. Windheuser, September 2019"
                        },
                        "1": {
                            "resource_type": "Technical guide",
                            "resource_text": "*[Monitoring Machine Learning Models in Production - A comprehensive guide](https://christophergs.com/machine%20learning/2020/03/14/how-to-monitor-machine-learning-models/)*, Christopher Samiullah, March 2020"
                        },
                        "2": {
                            "resource_type": "Web article",
                            "resource_text": "*[Google's medical AI was super accurate in a lab. Real life was a different story](https://www.technologyreview.com/2020/04/27/1000658/google-medical-ai-accurate-lab-real-life-clinic-covid-diabetes-retina-disease/)*, MIT Technology Review"
                        }
                    },
                    "answer_items": {
                        "3.5.a": {
                            "order_id": "a",
                            "answer_text": "The models we develop are not used in production systems",
                            "is_concerned_switch": 1,
                            "score_value": 0.0
                        },
                        "3.5.b": {
                            "order_id": "b",
                            "answer_text": "Performance is systematically re-evaluated when the model is updated",
                            "is_concerned_switch": 0,
                            "score_value": 0.5
                        },
                        "3.5.c": {
                            "order_id": "c",
                            "answer_text": "Performance is systematically re-evaluated when the context in which the model is used evolves, which may create a risk on the performance of the model due to the evolution of the input data space",
                            "is_concerned_switch": 0,
                            "score_value": 0.5
                        },
                        "3.5.d": {
                            "order_id": "d",
                            "answer_text": "The distribution of input data is monitored, and performance is regularly re-evaluated on the basis of updated test data",
                            "is_concerned_switch": 0,
                            "score_value": 0.5
                        },
                        "3.5.e": {
                            "order_id": "e",
                            "answer_text": "Random checks are carried out on predictions to check their consistency",
                            "is_concerned_switch": 0,
                            "score_value": 0.5
                        },
                        "3.5.f": {
                            "order_id": "f",
                            "answer_text": "We do not systematically set up this type of measure",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        }
                    },
                    "element_max_score": 2.0
                },
                "element 6": {
                    "order_id": "6",
                    "name": "Decision making and ranges of indecision",
                    "condition": "n/a",
                    "question_text": "n/a",
                    "question_type": "checkbox",
                    "answer_hint": "Select all response items that correspond to practices in your organisation. Please note that some combinations would not be coherent",
                    "explanation_text": "The study and selection of relevant decision thresholds for a given data science problem (*threshold selection*) is linked to the metrics selected. As discussed in the resources section of this evaluation issue, in some cases it may be worth considering the possibility of defining ranges of indecision.",
                    "resources": {
                        "0": {
                            "resource_type": "Web article",
                            "resource_text": "*[Opening the algorithm's black box and understand its outputs](https://medium.com/@asaboni/opening-the-algorithms-black-box-and-understand-its-outputs-e2363b0a887c)*, A. Saboni (Octo Technologies), April 2020"
                        }
                    },
                    "answer_items": {
                        "3.6.a": {
                            "order_id": "a",
                            "answer_text": "Operates informally on this subject and relies on the competence and responsibility of the collaborators involved",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        },
                        "3.6.b": {
                            "order_id": "b",
                            "answer_text": "Has a documented approach that is systematically implemented",
                            "is_concerned_switch": 0,
                            "score_value": 0.5
                        },
                        "3.6.c": {
                            "order_id": "c",
                            "answer_text": "Takes into account the possibility of maintaining ranges of indecision in certain cases",
                            "is_concerned_switch": 0,
                            "score_value": 0.67
                        },
                        "3.6.d": {
                            "order_id": "d",
                            "answer_text": "The choices made for each model and implemented are documented and integrated into the end-to-end genealogy of the models concerned.",
                            "is_concerned_switch": 0,
                            "score_value": 0.33
                        }
                    },
                    "element_max_score": 1.5
                },
                "element 7": {
                    "order_id": "7",
                    "name": "Audits by independent third parties and *verifiable claims*",
                    "condition": "n/a",
                    "question_text": "n/a",
                    "question_type": "checkbox",
                    "answer_hint": "Select one answer only, which best corresponds to the level of maturity of the organisation on this topic",
                    "explanation_text": "Developing a predictive model, and determining a meaningful and reliable benchmark performance measure, is a complex challenge. It is therefore often difficult for an organisation to assert that it has achieved excellent results and to claim them with certainty. Where possible, however, it may be even more difficult to make evidence publicly available without revealing valuable information about the organisation's intellectual property and the value of the work carried out. In such cases, it is recommended to have an audit carried out by an independent third party (e.g. security, privacy, fairness, reliability...), in order to secure the results the organisation wishes to claim.",
                    "resources": {
                        "0": {
                            "resource_type": "Academic paper",
                            "resource_text": "[Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable Claims](https://arxiv.org/pdf/2004.07213.pdf), §2 p.8-20, April 2020"
                        }
                    },
                    "answer_items": {
                        "3.7.a": {
                            "order_id": "a",
                            "answer_text": "We do not communicate or use the results or performance of our AI systems as an argument to our stakeholders, we are not concerned by this assessment element",
                            "is_concerned_switch": 1,
                            "score_value": 0.0
                        },
                        "3.7.b": {
                            "order_id": "b",
                            "answer_text": "We communicate on our results and rely on them for our development without first having our work audited by an independent third party, without making available any evidence",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        },
                        "3.7.c": {
                            "order_id": "c",
                            "answer_text": "We have our work audited by an independent third party, or we make evidence available, before communicating our results and using them to communicate and rely on with our stakeholders",
                            "is_concerned_switch": 0,
                            "score_value": 2.0
                        }
                    },
                    "element_max_score": 2.0
                }
            },
            "section_max_score": 12.5
        },
        "section 4": {
            "order_id": "4",
            "name": "Ensuring model reproducibility and establishing the chain of accountability",
            "keyword": "Model documentation",
            "description": "A predictive model is a complex object that can evolve over time. Tracing the stages of its development and evolution allows one to create a form of **genalogy**, which is a prerequisite for **reproducing or auditing** a model. Furthermore, using automatic systems based on models whose rules have been \"learned\" (and not defined and formalised) questions the way organisations operate. It seems essential to guarantee a clear chain of responsibility, of natural or legal persons, for each model.",
            "elements": {
                "element 1": {
                    "order_id": "1",
                    "name": "\"End-to-end genealogy\" of ML models",
                    "condition": "n/a",
                    "question_text": "n/a",
                    "question_type": "checkbox",
                    "answer_hint": "Select one answer only, which best corresponds to the level of maturity of the organisation on this topic",
                    "explanation_text": "This concept of the \"end-to-end genealogy\" of a learned predictive model can take the form, for example, of a reference document containing all the important choices and the entire history of model development (data used, pre-processing carried out, type of learning and model architecture, hyperparameters selected, decision thresholds, test metrics, etc.), and the internal processes organising this activity. In particular, it is interesting to include the trade-offs that have been made and why (e.g. trade-offs precision-specification, performance-privacy, performance-computing cost, etc.).",
                    "resources": {
                        "0": {
                            "resource_type": "Software & Tools",
                            "resource_text": "[Substra Framework](http://doc.substra.ai/): *an open source framework offering distributed orchestration of machine learning tasks among partners while guaranteeing secure and trustless traceability of all operations*"
                        },
                        "1": {
                            "resource_type": "Software & Tools",
                            "resource_text": "[MLflow](https://mlflow.org/): *an open source platform to manage the ML lifecycle, including experimentation, reproducibility, deployment, and a central model registry*"
                        },
                        "2": {
                            "resource_type": "Software & Tools",
                            "resource_text": "[DVC](https://dvc.org/): *an Open-source Version Control System for Machine Learning Projects*"
                        },
                        "3": {
                            "resource_type": "Software & Tools",
                            "resource_text": "[DAGsHub](https://dagshub.com/docs/): *a platform for data version control and collaboration, based on DVC* *a platform for data version control and collaboration, based on DVC*"
                        }
                    },
                    "answer_items": {
                        "4.1.a": {
                            "order_id": "a",
                            "answer_text": "At this stage we have not implemented any such approach",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        },
                        "4.1.b": {
                            "order_id": "b",
                            "answer_text": "This information exists and is recorded so as not to be lost, but it may be scattered and it is not versioned",
                            "is_concerned_switch": 0,
                            "score_value": 1.0
                        },
                        "4.1.c": {
                            "order_id": "c",
                            "answer_text": "They are compiled in a single document which systematically accompanies the model",
                            "is_concerned_switch": 0,
                            "score_value": 2.0
                        },
                        "4.1.d": {
                            "order_id": "d",
                            "answer_text": "They are gathered in a single document that systematically accompanies the model and is versioned",
                            "is_concerned_switch": 0,
                            "score_value": 2.5
                        }
                    },
                    "element_max_score": 5.5
                },
                "element 2": {
                    "order_id": "2",
                    "name": "Conditions and limitations for using a model",
                    "condition": "n/a",
                    "question_text": "n/a",
                    "question_type": "checkbox",
                    "answer_hint": "Select all response items that correspond to practices in your organisation. Please note that some combinations would not be coherent",
                    "explanation_text": "The aim is to make explicit and add to the model the description of the context of use for which it was designed and in which its announced performance is significant. This concept of \"conditions and limits of validity\" can take the form of a synthetic document or a specific section in the \"end-to-end genealogy\".",
                    "resources": {
                        "0": {
                            "resource_type": "Academic paper",
                            "resource_text": "[Model Cards for Model Reporting](https://arxiv.org/abs/1810.03993), M. Mitchell, S. Wu, A. Zaldivar, P. Barnes, L. Vasserman, B. Hutchinson, E. Spitzer, I. D. Raji, T. Gebru, January 2019"
                        },
                        "1": {
                            "resource_type": "Web article",
                            "resource_text": "[Model Cards](https://modelcards.withgoogle.com/about) from Google is an open and scalable framework, and offers 2 examples: *To explore the possibilities of model cards in the real world, we've designed examples for two features of our Cloud Vision API, Face Detection and Object Detection. They provide simple overviews of both models' ideal forms of input, visualize some of their key limitations, and present basic performance metrics.*"
                        }
                    },
                    "answer_items": {
                        "4.2.a": {
                            "order_id": "a",
                            "answer_text": "Are not documented",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        },
                        "4.2.b": {
                            "order_id": "b",
                            "answer_text": "Are explicited and documented",
                            "is_concerned_switch": 0,
                            "score_value": 1.0
                        },
                        "4.2.c": {
                            "order_id": "c",
                            "answer_text": "Are versioned",
                            "is_concerned_switch": 0,
                            "score_value": 0.5
                        },
                        "4.2.d": {
                            "order_id": "d",
                            "answer_text": "Contain a description of the risks involved in using the model outside its \"conditions and limits of validity\"",
                            "is_concerned_switch": 0,
                            "score_value": 1.0
                        },
                        "4.2.e": {
                            "order_id": "e",
                            "answer_text": "The documents presenting these \"conditions and limits of validity\" systematically accompany the models throughout their life cycle",
                            "is_concerned_switch": 0,
                            "score_value": 0.5
                        }
                    },
                    "element_max_score": 3.0
                },
                "element 3": {
                    "order_id": "3",
                    "name": "Analysis and publications of incidents reports",
                    "condition": "n/a",
                    "question_text": "n/a",
                    "question_type": "checkbox",
                    "answer_hint": "Select all response items that correspond to practices in your organisation. Please note that some combinations would not be coherent",
                    "explanation_text": "Understanding or even mastering the behaviour of a learned predictive model is a complex challenge. Lots of research is being done to develop methods and tools in this area, but much remains to be done. The sharing by practitioners of the unexpected incidents and behaviours they encounter contributes to the progress of the community.",
                    "resources": {
                        "0": {
                            "resource_type": "Software & Tools",
                            "resource_text": "[AI Incident Registry](http://aiid.partnershiponai.org/), Partnership on AI"
                        },
                        "1": {
                            "resource_type": "Web article",
                            "resource_text": "[Specification gaming examples in AI](https://docs.google.com/spreadsheets/d/e/2PACX-1vRPiprOaC3HsCf5Tuum8bRfzYUiKLRqJmbOoC-32JorNdfyTiRRsR6Ea5eWtvsWzuxo8bjOxCG84dAg/pubhtml), Victoria Krakovna"
                        },
                        "2": {
                            "resource_type": "Web article",
                            "resource_text": "[Learning from Tay's introduction](https://blogs.microsoft.com/blog/2016/03/25/learning-tays-introduction/): Incident analysis of the Tay chatbot, Microsoft, 2016"
                        },
                        "3": {
                            "resource_type": "Academic paper",
                            "resource_text": "[Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable Claims](https://arxiv.org/pdf/2004.07213.pdf), §2.4 p.19, April 2020"
                        }
                    },
                    "answer_items": {
                        "4.3.a": {
                            "order_id": "a",
                            "answer_text": "At this stage we do not analyse the incidents or unexpected behaviour observed",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        },
                        "4.3.b": {
                            "order_id": "b",
                            "answer_text": "We analyse incidents or unexpected behaviour encountered and publish them when relevant (e.g. article, blog)",
                            "is_concerned_switch": 0,
                            "score_value": 0.25
                        },
                        "4.3.c": {
                            "order_id": "c",
                            "answer_text": "We get involved in clubs, networks or professional associations in the field of data science, and give feedback on incidents of unexpected behaviour that we observe",
                            "is_concerned_switch": 0,
                            "score_value": 0.25
                        }
                    },
                    "element_max_score": 0.5
                },
                "element 4": {
                    "order_id": "4",
                    "name": "Value chain and chain of accountability",
                    "condition": "n/a",
                    "question_text": "n/a",
                    "question_type": "checkbox",
                    "answer_hint": "Select all response items that correspond to practices in your organisation. Please note that some combinations would not be coherent",
                    "explanation_text": "It is important to ensure that organisations upstream and downstream the chain identify and take responsibility for their segments of the value chain.",
                    "resources": {},
                    "answer_items": {
                        "4.4.a": {
                            "order_id": "a",
                            "answer_text": "Within our organisation, data science projects are carried out end-to-end by autonomous teams, including the elaboration of datasets and the exploitation of models for its own account. Consequently, for each project, an autonomous team is solely responsible",
                            "is_concerned_switch": 1,
                            "score_value": 0.0
                        },
                        "4.4.b": {
                            "order_id": "b",
                            "answer_text": "We systematically identify the risks and responsibilities of each of the internal and external stakeholders with whom we work",
                            "is_concerned_switch": 0,
                            "score_value": 1.5
                        },
                        "4.4.c": {
                            "order_id": "c",
                            "answer_text": "We systematically enter into contracts with upstream (e.g. data suppliers) and downstream (e.g. customers, model-using partners) players",
                            "is_concerned_switch": 0,
                            "score_value": 1.0
                        },
                        "4.4.d": {
                            "order_id": "d",
                            "answer_text": "We do not systematically implement this type of measure",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        }
                    },
                    "element_max_score": 2.5
                },
                "element 5": {
                    "order_id": "5",
                    "name": "Subcontracting of all or part of the data science activities",
                    "condition": "n/a",
                    "question_text": "n/a",
                    "question_type": "checkbox",
                    "answer_hint": "Select one answer only, which best corresponds to the level of maturity of the organisation on this topic",
                    "explanation_text": "As in the reference frameworks of IS management (ISO 27001) or GDPR in the European Union, it is important not to dilute responsibilities in uncontrolled subcontracting chains. This should apply, for example, to consultants, freelancers who come to reinforce an internal team on a data science project. For example, it is possible to ask sub-contractors to carry out the same evaluation on their own account and share their results with you.",
                    "resources": {},
                    "answer_items": {
                        "4.5.a": {
                            "order_id": "a",
                            "answer_text": "Not concerned, we do not subcontract these activities",
                            "is_concerned_switch": 1,
                            "score_value": 0.0
                        },
                        "4.5.b": {
                            "order_id": "b",
                            "answer_text": "Yes, our responses to this evaluation take into account the practices of our subcontractors",
                            "is_concerned_switch": 0,
                            "score_value": 1.5
                        },
                        "4.5.c": {
                            "order_id": "c",
                            "answer_text": "No, our answers to this evaluation do not apply to our subcontractors and on certain points they may be less advanced than us",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        }
                    },
                    "element_max_score": 1.5
                },
                "element 6": {
                    "order_id": "6",
                    "name": "Distribution of the value creation",
                    "condition": "n/a",
                    "question_text": "n/a",
                    "question_type": "checkbox",
                    "answer_hint": "Select all response items that correspond to practices in your organisation. Please note that some combinations would not be coherent",
                    "explanation_text": "When several partners work together to develop a model, it is important that the distribution of value resulting from an economic activity in which the model plays a role is made explicit and contractualized. In some cases this can be a complex issue, for example when a model is trained in a distributed manner over several datasets.",
                    "resources": {
                        "0": {
                            "resource_type": "Code repository",
                            "resource_text": "[Exploration of dataset contributivity to a model in collaborative ML projects](https://github.com/SubstraFoundation/distributed-learning-contributivity), an open source project led by [Substra Foundation](https://www.substra.ai/)"
                        }
                    },
                    "answer_items": {
                        "4.6.a": {
                            "order_id": "a",
                            "answer_text": "Our organisation carries out its data science activities autonomously, including the development of datasets and the exploitation of models for its own account. It is therefore not concerned",
                            "is_concerned_switch": 1,
                            "score_value": 0.0
                        },
                        "4.6.b": {
                            "order_id": "b",
                            "answer_text": "At this stage we have not structured this aspect of multi-partner data science projects",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        },
                        "4.6.c": {
                            "order_id": "c",
                            "answer_text": "In these cases, we contract the economic aspect of the relationship with the stakeholders involved upstream of the project",
                            "is_concerned_switch": 0,
                            "score_value": 1.0
                        },
                        "4.6.d": {
                            "order_id": "d",
                            "answer_text": "Our organisation has a policy that responsibly frames the sharing of value with the stakeholders involved",
                            "is_concerned_switch": 0,
                            "score_value": 1.0
                        }
                    },
                    "element_max_score": 2.0
                }
            },
            "section_max_score": 15.0
        },
        "section 5": {
            "order_id": "5",
            "name": "Using models responsibly and in confidence",
            "keyword": "Using the models",
            "description": "A predictive model can be used as an automatic system, whose rules or criteria are not written _in extenso_ and are difficult to explain, discuss or adjust. Using automatic systems based on predictive models whose rules have been \"learned\" (and not defined and formalised) therefore questions the way organisations design and operate their products and services. It is important to preserve the responsiveness and resilience of organisations using those predictive models, particularly in dealing with situations where predictive models have led to an undesirable outcome for the organisation or its stakeholders. In addition, efforts are therefore needed on the interpretation and explanation of the choices made using these systems.",
            "elements": {
                "element 1": {
                    "order_id": "1",
                    "name": "Exploitation of predictive models for one's own account",
                    "condition": "n/a",
                    "question_text": "n/a",
                    "question_type": "checkbox",
                    "answer_hint": "Select all response items that correspond to practices in your organisation. Please note that some combinations would not be coherent",
                    "explanation_text": "Using automatic systems based on models whose rules have been \"learned\" (and not defined and formalised) questions the way organisations design and operate their products and services. It is important to assess the consequences and reactions in the event of an incident. Furthermore, it is important that persons in charge is clearly identified so that no stakeholder is left helpless in the face of an unexpected or inappropriate consequence. Finally, it is important to consider the \"conditions and limits of validity\" of the models used to ensure that the intended use is appropriate.",
                    "resources": {},
                    "answer_items": {
                        "5.1.a": {
                            "order_id": "a",
                            "answer_text": "Our organisation does not use ML models on its own behalf",
                            "is_concerned_switch": 1,
                            "score_value": 0.0
                        },
                        "5.1.b": {
                            "order_id": "b",
                            "answer_text": "**A predictive models register** identifies all the models used by the organisation and is kept up-to-date",
                            "is_concerned_switch": 0,
                            "score_value": 1.0
                        },
                        "5.1.c": {
                            "order_id": "c",
                            "answer_text": "For each model there is an **owner** defined, identifiable and easily contactable",
                            "is_concerned_switch": 0,
                            "score_value": 0.5
                        },
                        "5.1.d": {
                            "order_id": "d",
                            "answer_text": "For each model, we systematically carry out a **risk assessment** following any incidents, failures or biases",
                            "is_concerned_switch": 0,
                            "score_value": 1.0
                        },
                        "5.1.e": {
                            "order_id": "e",
                            "answer_text": "Monitoring tools are put in place to ensure continuous monitoring of systems based on predictive models and can trigger alerts directly to the team in charge",
                            "is_concerned_switch": 0,
                            "score_value": 1.0
                        },
                        "5.1.f": {
                            "order_id": "f",
                            "answer_text": "For each model, we define and test a procedure for suspending the model and a degraded operating mode without the model, in order to prepare for the case where the model is subject to failure or unexpected behaviour",
                            "is_concerned_switch": 0,
                            "score_value": 1.0
                        },
                        "5.1.g": {
                            "order_id": "g",
                            "answer_text": "For each model, we study its entire genealogy (all the steps and choices that led to its development and evaluation), as well as its conditions and limits of validity, in order to understand the model before using it",
                            "is_concerned_switch": 0,
                            "score_value": 0.5
                        },
                        "5.1.h": {
                            "order_id": "h",
                            "answer_text": "We always use the models for **uses in accordance with their conditions and limits of validity**",
                            "is_concerned_switch": 0,
                            "score_value": 0.5
                        },
                        "5.1.i": {
                            "order_id": "i",
                            "answer_text": "We have not yet put in place such measures",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        }
                    },
                    "element_max_score": 5.5
                },
                "element 2": {
                    "order_id": "2",
                    "name": "Development of predictive models on behalf of third parties",
                    "condition": "n/a",
                    "question_text": "n/a",
                    "question_type": "checkbox",
                    "answer_hint": "Select all response items that correspond to practices in your organisation. Please note that some combinations would not be coherent",
                    "explanation_text": "Using automatic systems based on models whose rules have been \"learned\" (and not defined and formalised) questions the way organisations design and operate their products and services. It is important to assess the consequences and reactions in the event of an incident. Furthermore, it is important that persons in charge is clearly identified so that no stakeholder is left helpless in the face of an unexpected or inappropriate consequence. Finally, it is important to consider the \"conditions and limits of validity\" of the models used to ensure that the intended use is appropriate.",
                    "resources": {},
                    "answer_items": {
                        "5.2.a": {
                            "order_id": "a",
                            "answer_text": "Our organisation does not provide its customers or third parties, nor does it operates on behalf of third parties, with applications based on ML models",
                            "is_concerned_switch": 1,
                            "score_value": 0.0
                        },
                        "5.2.b": {
                            "order_id": "b",
                            "answer_text": "**A predictive models register** identifies all models or applications used by its customers and/or by the organisation on behalf of third parties, and is kept up-to-date",
                            "is_concerned_switch": 0,
                            "score_value": 1.0
                        },
                        "5.2.c": {
                            "order_id": "c",
                            "answer_text": "For each model or application for a customer or a third party we have a defined, identifiable and easily reachable **owner**",
                            "is_concerned_switch": 0,
                            "score_value": 0.5
                        },
                        "5.2.d": {
                            "order_id": "d",
                            "answer_text": "For each model or application for a customer or a third party, we systematically carry out a **risk assessment** resulting from possible incidents, failures, biases, etc., in order to identify the risks involved",
                            "is_concerned_switch": 0,
                            "score_value": 1.0
                        },
                        "5.2.e": {
                            "order_id": "e",
                            "answer_text": "Monitoring tools are in place to ensure continuous monitoring of ML systems and can trigger alerts directly to the responsible team",
                            "is_concerned_switch": 0,
                            "score_value": 1.0
                        },
                        "5.2.f": {
                            "order_id": "f",
                            "answer_text": "For each model or application for a customer or a third party, we define and test a procedure for suspending the model and a degraded operating mode without the model, in order to prepare for the case where the model is subject to failure or unexpected behaviour",
                            "is_concerned_switch": 0,
                            "score_value": 1.0
                        },
                        "5.2.g": {
                            "order_id": "g",
                            "answer_text": "For each model or application for a client or third party, we study its entire genealogy and its conditions and limits of validity to understand the model before using it",
                            "is_concerned_switch": 0,
                            "score_value": 0.5
                        },
                        "5.2.h": {
                            "order_id": "h",
                            "answer_text": "We supply our customers or operate on their behalf with models or applications for **uses in accordance with their conditions and limits of validity**",
                            "is_concerned_switch": 0,
                            "score_value": 0.5
                        },
                        "5.2.i": {
                            "order_id": "i",
                            "answer_text": "We have not yet put in place such measures",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        }
                    },
                    "element_max_score": 5.5
                },
                "element 3": {
                    "order_id": "3",
                    "name": "Management of problematic predictions, bypass process, _human agency_",
                    "condition": "n/a",
                    "question_text": "Automatic systems, especially when based on learned predictive models, are used in production generally to gain efficiency. By nature, they occasionally generate undesirable results for the organisation and its stakeholders (e.g. wrong prediction), as they will never achieve 100% performance.",
                    "question_type": "checkbox",
                    "answer_hint": "Select one answer only, which best corresponds to the level of maturity of the organisation on this topic",
                    "explanation_text": "Using automatic systems based on models whose rules have been \"learned\" (and not defined and formalised) questions the way organisations design and operate their products and services. It is important to preserve the responsiveness and resilience of the organisation.",
                    "resources": {
                        "0": {
                            "resource_type": "Technical guide",
                            "resource_text": "*[Monitoring Machine Learning Models in Production - A comprehensive guide](https://christophergs.com/machine%20learning/2020/03/14/how-to-monitor-machine-learning-models/)*, Christopher Samiullah, March 2020"
                        }
                    },
                    "answer_items": {
                        "5.3.a": {
                            "order_id": "a",
                            "answer_text": "Our organisation does not use predictive models developed by machine learning on its own behalf or on behalf of its clients, and does not provide its clients with applications based on predictive models",
                            "is_concerned_switch": 1,
                            "score_value": 0.0
                        },
                        "5.3.b": {
                            "order_id": "b",
                            "answer_text": "We implement ML models in integrated automatic systems, without mechanisms to overcome or avoid undesirable results due to model predictions",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        },
                        "5.3.c": {
                            "order_id": "c",
                            "answer_text": "We integrate, in automatic systems based on predictive models, the functionalities to manage these cases of undesirable results. For such cases, we set up mechanisms allowing a human operator to go against an automatic decision to manage such undesirable results or incidents",
                            "is_concerned_switch": 0,
                            "score_value": 0.5
                        },
                        "5.3.d": {
                            "order_id": "d",
                            "answer_text": "In addition to incident management mechanisms, in automatic systems based on predictive models, when the confidence interval for the automatic decision is not satisfactory a human operator is called upon",
                            "is_concerned_switch": 0,
                            "score_value": 1.0
                        },
                        "5.3.e": {
                            "order_id": "e",
                            "answer_text": "We systematically apply the principle of \"human agency\", the outputs of the predictive models that we implement are used by human operators, and do not serve as determinants for automatic decisions",
                            "is_concerned_switch": 0,
                            "score_value": 2.0
                        }
                    },
                    "element_max_score": 3.5
                },
                "element 4": {
                    "order_id": "4",
                    "name": "Explicability and interpretability",
                    "condition": "n/a",
                    "question_text": "n/a",
                    "question_type": "checkbox",
                    "answer_hint": "Select all response items that correspond to practices in your organisation. Please note that some combinations would not be coherent",
                    "explanation_text": "Explanability and interpretability are key issues, in line with the growing demands for transparency, impartiality and accountability. In some cases, regulations even impose it.\nTechnical resources such as SHAP or LIME provide a first-hand introduction to the topic (see resources associated with this assessment element).",
                    "resources": {
                        "0": {
                            "resource_type": "Web article",
                            "resource_text": "*[User confidence in systems involving Artificial Intelligence](https://blog.octo.com/la-confiance-des-utilisateurs-dans-les-systemes-impliquant-de-lintelligence-artificielle/)*, Blog Octo Technologies, October 2019"
                        },
                        "1": {
                            "resource_type": "Technical guide",
                            "resource_text": "*[Interpretable Machine Learning, A Guide for Making Black Box Models Explainable](https://christophm.github.io/interpretable-ml-book/)*, Christoph Molnar"
                        },
                        "2": {
                            "resource_type": "Web article",
                            "resource_text": "*[Understanding model predictions with LIME](https://towardsdatascience.com/understanding-model-predictions-with-lime-a582fdff3a3b)*, blog L. Hulstaert, 2018"
                        },
                        "3": {
                            "resource_type": "Software & Tools",
                            "resource_text": "*[SHAP](https://github.com/slundberg/shap): A game theoretic approach to explain the output of any machine learning model*."
                        },
                        "4": {
                            "resource_type": "Web article",
                            "resource_text": "In some cases, regulations impose being able to explain how an automated system came to a certain outcome (see for example [article 22 of the GDPR in the European Union](https://www.cnil.fr/fr/reglement-europeen-protection-donnees/chapitre3#Article22), [article 10 of the \"Informatique & Libertés\" law in France](https://www.legifrance.gouv.fr/affichTexteArticle.do;?idArticle=LEGIARTI000037090394&cidTexte=LEGITEXT000006068624&dateTexte=20180624), cited in particular in the [Hippocratic Oath for data scientist](https://hippocrate.tech/)."
                        }
                    },
                    "answer_items": {
                        "5.4.a": {
                            "order_id": "a",
                            "answer_text": "Our organisation is not yet familiar with the methods and tools for explaining and interpreting predictive models",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        },
                        "5.4.b": {
                            "order_id": "b",
                            "answer_text": "We are interested in the explicability and interpretability of predictive models and are in dialogue with our stakeholders on this subject",
                            "is_concerned_switch": 0,
                            "score_value": 0.25
                        },
                        "5.4.c": {
                            "order_id": "c",
                            "answer_text": "We ensure that the models we develop provide, when relevant, at least a level of confidence together with each prediction made",
                            "is_concerned_switch": 0,
                            "score_value": 0.25
                        },
                        "5.4.d": {
                            "order_id": "d",
                            "answer_text": "We determine the best compromises between performance and interpretability for each model we develop, which sometimes leads us to opt for a model that is simpler to explain to the stakeholders",
                            "is_concerned_switch": 0,
                            "score_value": 0.5
                        },
                        "5.4.e": {
                            "order_id": "e",
                            "answer_text": "We master and implement advanced approaches for the explicability and interpretability of models",
                            "is_concerned_switch": 0,
                            "score_value": 1.0
                        }
                    },
                    "element_max_score": 2.0
                },
                "element 5": {
                    "order_id": "5",
                    "name": "Transparency towards stakeholders interacting with a predictive model",
                    "condition": "n/a",
                    "question_text": "n/a",
                    "question_type": "checkbox",
                    "answer_hint": "Select all response items that correspond to practices in your organisation. Please note that some combinations would not be coherent",
                    "explanation_text": "Using automatic systems based on models whose rules have been \"learned\" (and not defined and formalised) questions the functioning of organisations but also the relationship of users to digital systems and services. In most cases it is important to inform users that they are not interacting with conventional business rules.",
                    "resources": {
                        "0": {
                            "resource_type": "Academic paper",
                            "resource_text": "*[Counterfactual Explanations without Opening the Black Box: Automated Decisions and the GDPR](https://arxiv.org/abs/1711.00399)*, S. Wachter, B. Mittelstadt, C. Russell, 2018"
                        },
                        "1": {
                            "resource_type": "Technical guide",
                            "resource_text": "*[Interpretable Machine Learning - Counterfactual explanations](https://christophm.github.io/interpretable-ml-book/counterfactual.html)*, C. Molnar, 2020"
                        }
                    },
                    "answer_items": {
                        "5.5.a": {
                            "order_id": "a",
                            "answer_text": "Our organisation does not use predictive models on its own behalf or on behalf of its clients, and does not provide its clients with applications based on predictive models",
                            "is_concerned_switch": 1,
                            "score_value": 0.0
                        },
                        "5.5.b": {
                            "order_id": "b",
                            "answer_text": "Users are not informed that they are interacting with a predictive model developed with machine learning methods",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        },
                        "5.5.c": {
                            "order_id": "c",
                            "answer_text": "An information notice is made available in the terms and conditions of the system or an equivalent document, freely accessible",
                            "is_concerned_switch": 0,
                            "score_value": 0.5
                        },
                        "5.5.d": {
                            "order_id": "d",
                            "answer_text": "The system or service is explicit to the user that a predictive model is being used",
                            "is_concerned_switch": 0,
                            "score_value": 0.5
                        },
                        "5.5.e": {
                            "order_id": "e",
                            "answer_text": "The system or service provides the user with additional information on the results it would have provided in slightly different scenarios (e.g. \"counterfactual explanations\" such as the smallest change in input data that would have resulted in a given different output)",
                            "is_concerned_switch": 0,
                            "score_value": 1.0
                        }
                    },
                    "element_max_score": 2.0
                }
            },
            "section_max_score": 18.5
        },
        "section 6": {
            "order_id": "6",
            "name": "Anticipating, monitoring and minimising the negative externalities of data science activities",
            "keyword": "Negative externalities",
            "description": "The implementation of an automatic system based on a predictive model can generate negative social and environmental externalities. Awareness of this is essential, as well as anticipating, monitoring and minimising the various negative impacts.",
            "elements": {
                "element 1": {
                    "order_id": "1",
                    "name": "CO2 impact",
                    "condition": "n/a",
                    "question_text": "n/a",
                    "question_type": "checkbox",
                    "answer_hint": "Select one answer only, which best corresponds to the level of maturity of the organisation on this topic",
                    "explanation_text": "It is important to question and raise awareness of environmental costs.",
                    "resources": {
                        "0": {
                            "resource_type": "Software & Tools",
                            "resource_text": "*[ML Impact Calculator](https://mlco2.github.io/impact/)*"
                        }
                    },
                    "answer_items": {
                        "6.1.a": {
                            "order_id": "a",
                            "answer_text": "At this stage we have not looked at the CO2 impact of our data science activity or our predictive models",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        },
                        "6.1.b": {
                            "order_id": "b",
                            "answer_text": "We have developed indicators that define what we want to measure",
                            "is_concerned_switch": 0,
                            "score_value": 0.67
                        },
                        "6.1.c": {
                            "order_id": "c",
                            "answer_text": "We measure our indicators regularly and include their measurements in the end-to-end genealogies of the models",
                            "is_concerned_switch": 0,
                            "score_value": 1.33
                        },
                        "6.1.d": {
                            "order_id": "d",
                            "answer_text": "Monitoring our indicators on a regular basis is a formalised and controlled process, from which we set ourselves improvement objectives",
                            "is_concerned_switch": 0,
                            "score_value": 2.0
                        }
                    },
                    "element_max_score": 4.0
                },
                "element 2": {
                    "order_id": "2",
                    "name": "Social impact",
                    "condition": "n/a",
                    "question_text": "n/a",
                    "question_type": "checkbox",
                    "answer_hint": "Select one answer only, which best corresponds to the level of maturity of the organisation on this topic",
                    "explanation_text": "It is important for an organisation to question and exchange with its stakeholders. This applies both downstream (e.g. automation of certain jobs) and upstream (e.g. data annotation tasks that can be very violent) the value chain.",
                    "resources": {},
                    "answer_items": {
                        "6.2.a": {
                            "order_id": "a",
                            "answer_text": "At this stage we are not looking at the social impact of our data science activity or our predictive models",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        },
                        "6.2.b": {
                            "order_id": "b",
                            "answer_text": "In some cases we study the social impact",
                            "is_concerned_switch": 0,
                            "score_value": 0.25
                        },
                        "6.2.c": {
                            "order_id": "c",
                            "answer_text": "We study the social impact in each project",
                            "is_concerned_switch": 0,
                            "score_value": 0.5
                        },
                        "6.2.d": {
                            "order_id": "d",
                            "answer_text": "We study the social impact in each project and it is documented in the end-to-end genealogy of each model",
                            "is_concerned_switch": 0,
                            "score_value": 1.25
                        },
                        "6.2.e": {
                            "order_id": "e",
                            "answer_text": "We study the social impact in each project, it is documented in the end-to-end genealogy of each model, and we systematically engage in a dialogue with the relevant stakeholders upstream and downstream the value chain.",
                            "is_concerned_switch": 0,
                            "score_value": 2.0
                        }
                    },
                    "element_max_score": 4.0
                },
                "element 3": {
                    "order_id": "3",
                    "name": "Ethics and non-maleficence",
                    "condition": "n/a",
                    "question_text": "n/a",
                    "question_type": "checkbox",
                    "answer_hint": "Select all response items that correspond to practices in your organisation. Please note that some combinations would not be coherent",
                    "explanation_text": "Working with large volumes of data, some of which may be sensitive, using automatic systems based on models whose rules have been \"learned\" (and not defined and formalised) raises questions about the way organisations function and the individual responsibility of each contributor. It requires considering carefully the uses of such sytems. It is therefore important for the organisation to ensure that ethical issues are not unknown to its collaborators.\nA recurring example is that some AI systems or services designed to adapt to user behaviour may influence users (e.g. by seeking to maximise their time of use or the money they spend) and present significant risks of manipulation or addiction.",
                    "resources": {
                        "0": {
                            "resource_type": "Official report",
                            "resource_text": "Rapport *[Ethics and Responsibility of Public Algorithms](https://www.etalab.gouv.fr/wp-content/uploads/2020/01/Rapport-ENA-Ethique-et-responsabilit%C3%A9-des-algorithmes-publics.pdf)*, Etalab / ENA, January 2020, in French"
                        },
                        "1": {
                            "resource_type": "Public declaration",
                            "resource_text": "*[Montreal Declaration for Responsible RNs](https://www.declarationmontreal-iaresponsable.com/la-declaration)*"
                        },
                        "2": {
                            "resource_type": "Public declaration",
                            "resource_text": "*[Holberton-Turing Oath](https://www.holbertonturingoath.org/accueil)*"
                        },
                        "3": {
                            "resource_type": "Public declaration",
                            "resource_text": "*[Hippocratic Oath for data scientist](https://hippocrate.tech/)*"
                        },
                        "4": {
                            "resource_type": "Public declaration",
                            "resource_text": "*[Future of Life's AI principles](https://futureoflife.org/ai-principles/)*"
                        },
                        "5": {
                            "resource_type": "Public declaration",
                            "resource_text": "*[International Charter for Inclusive AI](https://charteia.arborus.org/)*, Arborus and Orange"
                        },
                        "6": {
                            "resource_type": "Course",
                            "resource_text": "*[Practical data ethics](https://ethics.fast.ai/)*, fast.ai: an excellent online course combining reading lists and instructional videos"
                        }
                    },
                    "answer_items": {
                        "6.3.a": {
                            "order_id": "a",
                            "answer_text": "At this stage we have not yet addressed the ethical dimension of our data science projects",
                            "is_concerned_switch": 0,
                            "score_value": 0.0
                        },
                        "6.3.b": {
                            "order_id": "b",
                            "answer_text": "Employees involved in data science activities receive training in ethics",
                            "is_concerned_switch": 0,
                            "score_value": 1.0
                        },
                        "6.3.c": {
                            "order_id": "c",
                            "answer_text": "Our organisation has adopted an ethics policy",
                            "is_concerned_switch": 0,
                            "score_value": 1.0
                        },
                        "6.3.d": {
                            "order_id": "d",
                            "answer_text": "For projects justifying it, we set up an independent ethics committee or ask for the evaluation of an organisation validating the ethics of the projects",
                            "is_concerned_switch": 0,
                            "score_value": 1.0
                        }
                    },
                    "element_max_score": 3.0
                }
            },
            "section_max_score": 11.0
        }
    },
    "enriched_with_scoring": {
        "scoring_version": "1",
        "total_max_score": 79.83,
        "recap_per_section": {
            "section 1": 17.08,
            "section 2": 5.75,
            "section 3": 12.5,
            "section 4": 15.0,
            "section 5": 18.5,
            "section 6": 11.0
        }
    },
    "non_concerned_recap": {
        "non_concerned_in_element": {
            "3.2": 0.75,
            "3.5": 1.0,
            "3.7": 1.0,
            "4.4": 1.25,
            "4.5": 0.75,
            "4.6": 1.0,
            "5.1": 2.75,
            "5.2": 2.75,
            "5.3": 1.75,
            "5.5": 1.0
        },
        "conditional_elements": {}
    }
}